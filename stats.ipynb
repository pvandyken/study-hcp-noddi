{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots()\n",
    "# hack to remove hide globally installed libraries, which are the wrong R version\n",
    "from rpy2 import robjects as ro\n",
    "\n",
    "ro.r(\".libPaths('/local/scratch/gt/lib/R/library')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from pathlib import Path\n",
    "\n",
    "import ciftipy as cp\n",
    "import colormaps as cmaps\n",
    "import dask.bag as db\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import scipy.stats as scs\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import statsmodels.formula.api as smf\n",
    "import xarray as xr\n",
    "from brainspace.plotting import plot_surf\n",
    "from brainstat.datasets import fetch_mask, fetch_template_surface\n",
    "from brainstat.stats.SLM import SLM\n",
    "from brainstat.stats.terms import FixedEffect, MixedEffect\n",
    "from dask.diagnostics import ProgressBar\n",
    "from matplotlib import cm, font_manager\n",
    "from rsbids import BidsLayout\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "from lib import atlases\n",
    "from lib.bidsarray import layout_map\n",
    "from lib.dataset import Dataset\n",
    "from lib.mesh import mesh_smooth\n",
    "from lib import polars_expr as ple\n",
    "from lib.plotting import (\n",
    "    add_colorbar,\n",
    "    add_legend,\n",
    "    comparison_plot,\n",
    "    plot_hierachical_connectome,\n",
    ")\n",
    "from lib.seaborn_stats import Lme4CI\n",
    "from styles import styles as Styles\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.style.use(\"styles/manuscript.mplstyle\")\n",
    "font_dirs = [Path.home() / \".fonts\"]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.ipython.html\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "rpy2.ipython.html.init_printing()\n",
    "\n",
    "\n",
    "rutils = importr(\"utils\")\n",
    "rbase = importr(\"base\")\n",
    "lme4 = importr(\"lme4\")\n",
    "rstats = importr(\"stats\")\n",
    "pbkrtest = importr(\"pbkrtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout = BidsLayout(\n",
    "#     [\"../../derivatives/surfsample-0.1.0/\", \"../../derivatives/snakeanat-diffusion-v0.0.1/\"],\n",
    "#     cache=\".cache\",\n",
    "#     reset_cache=True,\n",
    "# )\n",
    "hcp = (\n",
    "    Dataset(\".hcp.layout\", \"hcp\")\n",
    "    .add_phenotypes(\"hcp_metadata.yaml\")\n",
    "    .filter(pl.col(\"ddx\").is_in([1, 3]))\n",
    ")\n",
    "lh, rh = fetch_template_surface(\"fslr32k\", layer=\"vinflated\", join=False)\n",
    "mesh = fetch_template_surface(\"fslr32k\", layer=\"inflated\")\n",
    "mask = fetch_mask(\"fslr32k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all the surface sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hems(img):\n",
    "    l = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project(0).flatten()\n",
    "    r = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project(0).flatten()\n",
    "    return l, r\n",
    "\n",
    "\n",
    "@layout_map(parallel=True, dtype=float, dims={\"vertex\": 64984})\n",
    "def load_data(path):\n",
    "    img = cp.load(path)\n",
    "    lh, rh = get_hems(img)\n",
    "    data = np.full((lh.shape[0] + rh.shape[0]), np.NaN)\n",
    "    bound = lh.shape[0]\n",
    "    data[:bound] = lh\n",
    "    data[bound:] = rh\n",
    "    return data\n",
    "\n",
    "    # jhp_surface = load_data(\n",
    "    #     jhp.layout.get(suffix=[\"curv\", \"thickness\"], den=\"32k\"),\n",
    "    #     [\"subject\", \"session\", \"suffix\"],\n",
    "    # ).to_dataset(name=\"surface\")\n",
    "    # jhp_surface.to_netcdf(\"checkpoint2.h5\")\n",
    "\n",
    "\n",
    "hcp_surface = xr.concat(\n",
    "    [\n",
    "        load_data(\n",
    "            hcp.layout.get(suffix=\"mdp\", extension=\".dscalar.nii\"),\n",
    "            [\"subject\", \"desc\"],\n",
    "        ),\n",
    "        load_data(\n",
    "            hcp.layout.filter(scope=\"hcp-preproc\").get(\n",
    "                suffix=\"thickness\", den=\"32k\", desc=\"corr\"\n",
    "            ),\n",
    "            [\"subject\", \"suffix\"],\n",
    "        ).rename(suffix=\"desc\"),\n",
    "    ],\n",
    "    dim=\"desc\",\n",
    ")\n",
    "# with ProgressBar():\n",
    "#     hcp_surface.to_netcdf(\"hcp_surface.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_surface = xr.open_dataarray(\"hcp_surface.nc\", chunks={})\n",
    "hcp_surface_smooth = xr.concat(\n",
    "    [\n",
    "        mesh_smooth(\n",
    "            hcp_surface.where(mask),\n",
    "            surf=mesh,\n",
    "            FWHM=smoothing,\n",
    "            mask=mask,\n",
    "            axis=\"vertex\",\n",
    "\n",
    "        ).expand_dims(smoothing=[smoothing])\n",
    "        for smoothing in np.r_[5:15]\n",
    "    ],\n",
    "    dim=\"smoothing\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    hcp_surface_smooth.to_netcdf(\"hcp_surface_smooth.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkmd = pd.read_csv(\"atlas-dkt_labels.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "@layout_map(\n",
    "    parallel=True,\n",
    "    dims={\"param\": hcp_surface[\"desc\"].rename(desc=\"param\"), \"roi\": dkmd[\"label\"]},\n",
    "    dtype=float,\n",
    ")\n",
    "def sample_dk(path):\n",
    "    dknii = cp.load(path)\n",
    "    dkatlas = np.empty(32492 * 2)\n",
    "    dkatlas[:32492] = (\n",
    "        dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project().ravel()\n",
    "    )\n",
    "    dkatlas[32492:] = (\n",
    "        dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project().ravel()\n",
    "    )\n",
    "    result = np.empty((len(hcp_surface[\"desc\"]), len(dkmd)))\n",
    "    x = hcp_surface.sel(subject=path.entities[\"subject\"])\n",
    "    for (i, param), (j, label) in it.product(\n",
    "        enumerate(hcp_surface[\"desc\"]), enumerate(dkmd[\"label\"])\n",
    "    ):\n",
    "        result[i, j] = np.mean(x.sel(desc=param)[dkatlas == label])\n",
    "    return result\n",
    "\n",
    "\n",
    "dk_sample = (\n",
    "    sample_dk(\n",
    "        hcp.layout.get(\n",
    "            suffix=\"dparc\",\n",
    "            subject=hcp_surface[\"subject\"].data,\n",
    "            atlas=\"dk\",\n",
    "            space=\"fsLR\",\n",
    "            den=\"32k\",\n",
    "        ),\n",
    "        wildcards=[\"subject\"],\n",
    "    )\n",
    "    .to_dataset(name=\"dk\")\n",
    "    .merge(dkmd.rename(columns={\"label\": \"roi\"}).set_index(\"roi\").to_xarray())\n",
    ")\n",
    "with ProgressBar():\n",
    "    dk_sample.to_netcdf(\"hcp_dk_sample.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_surface = xr.open_dataarray(\"hcp_surface.nc\", chunks={})\n",
    "hcp_sampled = xr.load_dataset(\"hcp_dk_sample.nc\")\n",
    "def get_stds(df):\n",
    "    return df.with_columns(\n",
    "        stds=(\n",
    "            pl.col.dk.map_elements(scs.zscore, return_dtype=pl.List(float))\n",
    "            .abs()\n",
    "            .over(\"lobe\", \"param\", \"group\")\n",
    "        )\n",
    "    ).with_columns(\n",
    "        pl.col.stds.floor().cast(int).sub(1).clip(0, 5).sum().over(\"subject\")\n",
    "    )\n",
    "hcp_df = (\n",
    "    hcp_sampled.to_dataframe()\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .filter(~pl.col.roi.is_in([4, 39]))\n",
    "    .group_by(\"subject\", \"param\", \"lobe\", \"hemisphere\")\n",
    "    .agg(pl.mean(\"dk\"))\n",
    "    .filter(pl.col.subject != \"1032\")\n",
    "    # .filter(pl.col.param.is_in([\"FA\", \"ndi\", \"odi\", \"fw\", \"thickness\"]))\n",
    "    .join(\n",
    "        hcp.metadata[[\"subject\", \"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]],\n",
    "        on=\"subject\",\n",
    "    )\n",
    "    .pipe(get_stds)\n",
    "    # .filter(~pl.col.subject.is_in([\"2004\", \"4010\"]))\n",
    ")\n",
    "std_thresh = 30\n",
    "dropped_subs = list(hcp_df.filter(pl.col.stds >= std_thresh)[\"subject\"].unique())\n",
    "hcp_df = hcp_df.filter(pl.col.stds < std_thresh)\n",
    "hcp_smooth = xr.open_dataarray(\"hcp_surface_smooth.nc\", chunks={}).drop_sel(\n",
    "    subject=[*dropped_subs, \"3034\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Surface Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest\n",
    "\n",
    "from lib import polars_expr as ple\n",
    "\n",
    "hcp_glob_df = (\n",
    "    hcp_sampled.to_dataframe()\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .filter(~pl.col.roi.is_in([4, 39]))\n",
    "    .group_by(\"subject\", \"param\", \"hemisphere\")\n",
    "    .agg(pl.mean(\"dk\"))\n",
    "    .join(\n",
    "        hcp.metadata[[\"subject\", \"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]],\n",
    "        on=\"subject\",\n",
    "    )\n",
    "    .filter(~pl.col.subject.is_in([*dropped_subs, \"1032\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_glob_stats = (\n",
    "    hcp_glob_df\n",
    "    .group_by(\"param\")\n",
    "    .agg(\n",
    "        ple.mixedlm(\n",
    "            \"scale(dk) ~ scale(age) + sex + hemisphere*group\", groups=\"subject\"\n",
    "        ).alias(\"stats\")\n",
    "    )\n",
    "    .unnest(\"stats\")\n",
    "    .explode(\"table\")\n",
    "    .unnest(\"table\")\n",
    "    .filter(\n",
    "        pl.col.index.is_in(\n",
    "            [\"hemisphere[T.R]\", \"group[T.Patient]\", \"hemisphere[T.R]:group[T.Patient]\"]\n",
    "        )\n",
    "    )\n",
    "    .with_columns(\n",
    "        pval=pl.when(\n",
    "            pl.col.index == \"group[T.Patient]\",\n",
    "            pl.col.param.is_in([\"ndi\", \"odi\", \"fw\", \"thickness\"]),\n",
    "        )\n",
    "        .then(pl.col.pval / 2)\n",
    "        .otherwise(pl.col.pval)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pvalcorr=pl.col.pval.map_elements(\n",
    "            lambda a: pl.Series(multitest.multipletests(a, method=\"holm\")[1]),\n",
    "            return_dtype=pl.List(float),\n",
    "        ).over(\"param\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_glob_stats.filter(pl.col.pvalcorr < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = hcp_glob_df.pivot(\n",
    "    index=[\"subject\", \"age\", \"sex\", \"hemisphere\", \"group\", \"PANSSP\", \"PANSSN\"],\n",
    "    columns=\"param\",\n",
    "    values=\"dk\",\n",
    ").with_columns(cs.matches(\"MD|L1|RD\") * 1000)\n",
    "fig = plt.figure(figsize=(8, 6), layout=\"constrained\")\n",
    "axs = fig.subplots(3, 3)\n",
    "axs[0, 0].text(-0.17, 1.03, \"A\", **Styles.panel_label, transform=axs[0, 0].transAxes)\n",
    "axs[1, 0].text(-0.17, 1.03, \"B\", **Styles.panel_label, transform=axs[1, 0].transAxes)\n",
    "\n",
    "\n",
    "ylabels = {\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"fw\": \"$f_{fw}$\",\n",
    "    \"thickness\": \"Thickness (mm)\",\n",
    "    \"FA\": \"FA\",\n",
    "    \"MD\": r\"MD ($\\frac{\\mu m^2}{ms}$)\",\n",
    "    \"RD\": r\"RD ($\\frac{\\mu m^2}{ms}$)\",\n",
    "}\n",
    "params = [\"thickness\", \"fw\", \"ndi\"]\n",
    "for i, (y, x) in enumerate(np.ndindex(1, 3)):\n",
    "    ax = axs[y, x]\n",
    "    if params[i] in {\"thickness\", \"fw\"}:\n",
    "        sig = {\n",
    "            (\"HC\", \"Patient\"): hcp_glob_stats.filter(\n",
    "                param=params[i], index=\"group[T.Patient]\"\n",
    "            )[\"pvalcorr\"][0]\n",
    "        }\n",
    "    else:\n",
    "        sig = None\n",
    "    comparison_plot(\n",
    "        _df.to_pandas(),\n",
    "        y=params[i],\n",
    "        x=\"group\",\n",
    "        hue=\"group\",\n",
    "        ax=ax,\n",
    "        alpha=0.7,\n",
    "        size=3,\n",
    "        order=[\"HC\", \"Patient\"],\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        significance=sig,\n",
    "    )\n",
    "    ax.set_ylabel(ylabels[params[i]])\n",
    "    ax.set_xlabel(\"Group\")\n",
    "    ax.set_xticks([1, 0])\n",
    "\n",
    "params = [\"thickness\", \"fw\", \"ndi\", \"FA\", \"MD\", \"RD\"]\n",
    "for i, (y, x) in enumerate(np.ndindex(2, 3)):\n",
    "    (\n",
    "        so.Plot(_df, y=params[i], x=\"hemisphere\", color=\"group\", linestyle=\"group\")\n",
    "        .add(so.Dot(pointsize=3, alpha=0.7), so.Jitter(), legend=False)\n",
    "        .add(so.Line(linewidth=2), so.PolyFit(1), legend=False)\n",
    "        .add(so.Band(), Lme4CI(nsims=500), group=\"subject\", legend=False)\n",
    "        .on(axs[y + 1, x])\n",
    "        .label(x=\"\" if i < 3 else \"Hemisphere\", y=ylabels[params[i]])\n",
    "        .scale(\n",
    "            x=so.Nominal(order=[\"L\", \"R\"]), color=so.Nominal(order=[\"HC\", \"Patient\"])\n",
    "        )\n",
    "        .plot()\n",
    "    )\n",
    "add_legend(\n",
    "    fig,\n",
    "    [\"HC\", \"Patient\"],\n",
    "    cmap=cm.tab10,\n",
    "    fontsize=12,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.37, 0.33),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-surf-global\n",
    "---\n",
    "Cortical thickness reduced and $f_{fw}$ increased in patients. Statistics computed using linear mixed-effects models with subject as a random effect and group, hemisphere, age, and sex as fixed effects. For each parameter, two-tailed Z-tests were used to evaluate the effect of group, hemisphere, and group-hemisphere interaction on the parameter. One-tailed Z-tests were instead used for group effects on NDI, ODI, thickness (reduced in patients), and $f_{fw}$ (increased in patients). P-values from the three contrasts were corrected using Holm-Bonferonni corrections. A. Average cortical thickness is significantly lower ($Z=-5.0;P<.001$) and $f_{fw}$ significantly higher ($Z=2.2;P=.013$) in Patients versus controls. B. Thickness, NDI, $f_{fw}$, MD, and RD have significant hemisphere effects. RD has a significant group-hemisphere interaction effect. Statistics shown in @tbl-surf-global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.001)\n",
    "    .then(pl.lit(\"< .001\"))\n",
    "    .otherwise(\n",
    "        pl.col(\"pvalcorr\")\n",
    "        .round(3)\n",
    "        .round_sig_figs(2)\n",
    "        .cast(str)\n",
    "        .str.strip_chars_start(\"0\")\n",
    "    )\n",
    ")\n",
    "sig_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.05)\n",
    "    .then(pl.format(r\"\\textbf{{}}\", p_format))\n",
    "    .otherwise(p_format)\n",
    ")\n",
    "print(\n",
    "    hcp_glob_stats\n",
    "    .select(\n",
    "        pl.col.coef.round_sig_figs(2)\n",
    "        .cast(str)\n",
    "        .str.strip_chars_end(\"0\")\n",
    "        .alias(r\"$\\beta_{norm}$\"),\n",
    "        pl.col.z.round_sig_figs(2).cast(str).str.strip_chars_end(\"0\").alias(\"Z\"),\n",
    "        sig_format.alias(r\"$P_{corr}$\"),\n",
    "        index=pl.col.index.replace(\n",
    "            {\n",
    "                \"hemisphere[T.R]\": r\"$\\sim Hem_{right}$\",\n",
    "                \"group[T.Patient]\": r\"$\\sim G_{patient}$\",\n",
    "                \"hemisphere[T.R]:group[T.Patient]\": r\"$\\sim Hem_{right}:G_{patient}$\",\n",
    "            }\n",
    "        ),\n",
    "        param=pl.col.param.replace(\n",
    "            {\n",
    "                \"ndi\": \"NDI\",\n",
    "                \"fw\": \"$f_{fw}$\",\n",
    "                \"odi\": \"ODI\",\n",
    "                \"thickness\": \"Thickness\",\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index([\"param\", \"index\"])\n",
    "    .sort_index()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], axis=1)\n",
    "    .sort_index(axis=1)\n",
    "    .reindex([r\"$\\beta_{norm}$\", \"Z\", r\"$P_{corr}$\"], axis=1, level=1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"\": \"Param\", \"param\": \"\"})\n",
    "    .style.hide()\n",
    "    .to_latex(\n",
    "        column_format=\"rlllllllll\",\n",
    "        hrules=True,\n",
    "        multicol_align=\"c\",\n",
    "        convert_css=True,\n",
    "        label=\"tbl-surf-global\",\n",
    "        caption=\"Statistics for average cortical parameters modelled against group and hemisphere.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import polars_expr as ple\n",
    "\n",
    "\n",
    "def get_ols(col, filter=None):\n",
    "    if col == \"group\":\n",
    "        contr = \"group[T.Patient]\"\n",
    "    else:\n",
    "        contr = col\n",
    "    return ple.ols(\n",
    "        f\"scale(dk) ~ {col} + scale(age) + sex\",\n",
    "        contr,\n",
    "        filter=filter,\n",
    "        columns=\"param\",\n",
    "        alternative=pl.when(pl.col.param.is_in([\"fw\", \"RD\", \"MD\", \"L1\"]))\n",
    "        .then(pl.lit(1))\n",
    "        .when(pl.col.param == \"FA\")\n",
    "        .then(pl.lit(0))\n",
    "        .otherwise(pl.lit(-1)),\n",
    "    ).alias(f\"{col}_stats\")\n",
    "\n",
    "\n",
    "def get_all_stats(df):\n",
    "    return (\n",
    "        df.group_by(\"lobe\", \"param\", \"hemisphere\")\n",
    "        .agg(\n",
    "            get_ols(\"group\"),\n",
    "            # get_ols(\"PANSSP\", pl.col.group == \"Patient\"),\n",
    "            # get_ols(\"PANSSN\", pl.col.group == \"Patient\"),\n",
    "        )\n",
    "        .melt([\"param\", \"lobe\", \"hemisphere\"], cs.matches(\".*_stats\"), \"model\", \"stats\")\n",
    "        .with_columns(pl.col(\"model\").str.split(\"_\").list.first())\n",
    "        .unnest(\"stats\")\n",
    "        .with_columns(\n",
    "            pl.col(\"pval\")\n",
    "            .map_elements(\n",
    "                lambda x: pl.Series(scs.false_discovery_control(x)),\n",
    "                return_dtype=pl.List(pl.Float64),\n",
    "            )\n",
    "            .over(\"param\", \"model\")\n",
    "            .name.suffix(\"corr\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "hcp_stats = get_all_stats(\n",
    "    hcp_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "roi_pvalues = hcp_stats.join(\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"param\": [*([\"fw\"] * 6), \"FA\"],\n",
    "            \"lobe\": [*([\"insula\", \"occipital\", \"temporal\"] * 2), \"insula\"],\n",
    "            \"hemisphere\": [*([\"L\", \"R\"] * 3), \"L\"],\n",
    "        }\n",
    "    ),\n",
    "    on=[\"param\", \"lobe\", \"hemisphere\"],\n",
    ").filter(model=\"group\")[[\"param\", \"lobe\", \"hemisphere\", \"pvalcorr\"]]\n",
    "\n",
    "_df = hcp_df.pivot(\n",
    "    index=[\"subject\", \"lobe\", \"hemisphere\", \"group\"], columns=\"param\", values=\"dk\"\n",
    ")\n",
    "fig = plt.figure(figsize=(8, 5), layout=\"constrained\")\n",
    "axs = fig.subplots(2, 2)\n",
    "params = [\"fw\", \"fw\", \"fw\", \"FA\"]\n",
    "lobes = [\"insula\", \"occipital\", \"temporal\", \"insula\"]\n",
    "labels = {\n",
    "    \"fw\": \"$f_{fw}$\",\n",
    "    \"FA\": \"FA\",\n",
    "}\n",
    "\n",
    "for i, (y, x) in enumerate(np.ndindex(2, 2)):\n",
    "    ax = axs[y, x]\n",
    "    __df = _df.filter(lobe=lobes[i])\n",
    "    sns.stripplot(\n",
    "        __df,\n",
    "        y=params[i],\n",
    "        x=\"hemisphere\",\n",
    "        hue=\"group\",\n",
    "        dodge=True,\n",
    "        legend=False,\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"L\", \"R\"],\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.violinplot(\n",
    "        __df,\n",
    "        y=params[i],\n",
    "        x=\"hemisphere\",\n",
    "        hue=\"group\",\n",
    "        split=True,\n",
    "        legend=False,\n",
    "        palette=([cm.tab10(0), cm.tab10(1)]),\n",
    "        alpha=0.4,\n",
    "        linecolor=\"#f0f0f0\",\n",
    "        linewidth=1,\n",
    "        inner=\"quart\",\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"L\", \"R\"],\n",
    "        ax=ax,\n",
    "        cut=0,\n",
    "    )\n",
    "    ax.set_title(lobes[i].capitalize())\n",
    "    ax.set_xlabel(\"\" if i < 2 else \"Hemisphere\")\n",
    "    ax.set_ylabel(labels[params[i]])\n",
    "    if (lett_ := {0: \"A\", 3: \"B\"}.get(i)) is not None:\n",
    "        ax.text(-0.18, 1.03, lett_, **Styles.panel_label, transform=ax.transAxes)\n",
    "    if i == 3:\n",
    "        # ax.set_facecolor(\"white\")\n",
    "        fig.patches.append(\n",
    "            plt.Rectangle(\n",
    "                (-0.2, -0.25),\n",
    "                1.3,\n",
    "                1.4,\n",
    "                transform=ax.transAxes,\n",
    "                color=\"#e0e0e0\",\n",
    "                zorder=-1,\n",
    "            )\n",
    "        )\n",
    "    hemis, pvals = roi_pvalues.filter(param=params[i], lobe=lobes[i])[\n",
    "        [\"hemisphere\", \"pvalcorr\"]\n",
    "    ]\n",
    "    annot = Annotator(\n",
    "        ax,\n",
    "        data=__df.to_pandas(),\n",
    "        y=params[i],\n",
    "        x=\"hemisphere\",\n",
    "        hue=\"group\",\n",
    "        order=[\"L\", \"R\"],\n",
    "        pairs=[((h, \"HC\"), (h, \"Patient\")) for h in hemis],\n",
    "        verbose=False,\n",
    "    )\n",
    "    annot.hide_not_significant = True\n",
    "    annot.configure(test=None).set_pvalues(pvals).annotate()\n",
    "    \n",
    "add_legend(fig, [\"HC\", \"Patient\"], cmap=cm.tab10, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-surf-roi\n",
    "---\n",
    "Cortical ROIs affected in early psychosis. P-values corrected for multiple comparisons across ROIs for each parameter using FDR. A. ROIs with significantly higher $f_{fw}$ in both hemispheres. B. The insula has lower FA in the left hemisphere only. Statistics shown in @tbl-surf-roi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "p_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.001)\n",
    "    .then(pl.lit(\"< .001\"))\n",
    "    .otherwise(\n",
    "        pl.col(\"pvalcorr\")\n",
    "        .round(3)\n",
    "        .round_sig_figs(2)\n",
    "        .cast(str)\n",
    "        .str.strip_chars_start(\"0\")\n",
    "    )\n",
    ")\n",
    "sig_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.05)\n",
    "    .then(pl.format(r\"\\textbf{{}}\", p_format))\n",
    "    .otherwise(p_format)\n",
    ")\n",
    "\n",
    "\n",
    "def format_stats_table(df, label, caption):\n",
    "    df_resid = df[\"df_resid\"].cast(int)[0]\n",
    "    return (\n",
    "        df.select(\n",
    "            pl.col.param.replace({\"thickness\": \"Thickness\", \"fw\": \"$f_{fw}$\"}).alias(\n",
    "                \"Param\"\n",
    "            ),\n",
    "            pl.format(\"{}-{}\", pl.col.hemisphere, pl.col.lobe.str.to_titlecase()).alias(\n",
    "                \"Lobe\"\n",
    "            ),\n",
    "            pl.col.beta.round_sig_figs(2)\n",
    "            .cast(str)\n",
    "            .str.strip_chars_end(\"0\")\n",
    "            .alias(r\"$\\beta_{norm}$\"),\n",
    "            pl.col.statistic.round_sig_figs(2)\n",
    "            .cast(str)\n",
    "            .str.strip_chars_end(\"0\")\n",
    "            .alias(f\"$T({df_resid})$\"),\n",
    "            sig_format.alias(\"$P_{corr}$\"),\n",
    "        )\n",
    "        .to_pandas()\n",
    "        .set_index([\"Param\", \"Lobe\"])\n",
    "        .sort_index()\n",
    "        .style.to_latex(\n",
    "            column_format=\"rrlll\",\n",
    "            hrules=True,\n",
    "            multicol_align=\"c\",\n",
    "            multirow_align=\"t\",\n",
    "            convert_css=True,\n",
    "            label=label,\n",
    "            caption=caption,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\n",
    "    format_stats_table(\n",
    "        hcp_stats.filter(pl.col.pvalcorr < 0.05, model=\"group\"),\n",
    "        \"tbl-surf-roi\",\n",
    "        textwrap.dedent(\n",
    "            \"\"\"\n",
    "            ROIs with a significant group effect on any of the parameters Thickness,\n",
    "            NDI, ODI, f_fw, FA, MD, RD, or AD. Comparisons across lobes corrected using\n",
    "            FDR.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Vertex-wise stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = (\n",
    "    hcp_smooth.to_dataset(name=\"data\")\n",
    "    .merge(\n",
    "        hcp.metadata[[\"subject\", \"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]]\n",
    "        .to_pandas()\n",
    "        .set_index(\"subject\"),\n",
    "        join=\"inner\",\n",
    "    )\n",
    ")\n",
    "ds_pt = ds.groupby(\"group\")[\"Patient\"]\n",
    "# ds_ = ds_.sel(subject=~np.isnan(ds_[\"PANSS-N\"]))\n",
    "\n",
    "surface = ds[\"data\"].transpose(\"desc\", \"smoothing\", \"subject\", \"vertex\")\n",
    "df = ds[[\"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]].to_dataframe()\n",
    "df_pt = ds_pt[[\"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]].to_dataframe()\n",
    "term_group = FixedEffect(df[\"group\"])\n",
    "term_age = FixedEffect(df[\"age\"])\n",
    "term_sex = FixedEffect(df[\"sex\"])\n",
    "term_panssn = FixedEffect(df_pt[\"PANSSN\"])\n",
    "term_panssp = FixedEffect(df_pt[\"PANSSP\"])\n",
    "\n",
    "group_pt = np.asarray(df[\"group\"] == \"Patient\").astype(int)\n",
    "group_hc = np.asarray(df[\"group\"] == \"HC\").astype(int)\n",
    "\n",
    "models = {\n",
    "    \"group\": {\n",
    "        \"model\": term_group + term_age + term_sex,\n",
    "        \"contrast\": group_hc - group_pt,\n",
    "        \"surface\": surface,\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "from brainstat.stats.SLM import SLM\n",
    "from brainstat.stats.terms import FixedEffect, MixedEffect\n",
    "\n",
    "signs = {\n",
    "    \"fw\": -1,\n",
    "    \"thickness\": 1\n",
    "}\n",
    "\n",
    "def compute_stats(ds):\n",
    "    smoothing = ds[\"smoothing\"].item()\n",
    "    suffix = ds[\"suffix\"].item()\n",
    "    sign = signs[suffix]\n",
    "    model = models[ds[\"model\"].item()]\n",
    "    slm = SLM(\n",
    "        model[\"model\"],\n",
    "        model[\"contrast\"] * sign,\n",
    "        mask=mask,\n",
    "        surf=\"fslr32k\",\n",
    "        correction=[\"rft\", \"fdr\"],\n",
    "        cluster_threshold=0.01,\n",
    "        two_tailed=False,\n",
    "    )\n",
    "    try:\n",
    "        slm.fit(\n",
    "            np.asanyarray(\n",
    "                model[\"surface\"].sel(desc=suffix, smoothing=smoothing).fillna(0)\n",
    "            )\n",
    "        )\n",
    "    except np.linalg.LinAlgError:\n",
    "        entries = {\n",
    "            \"C\": None,\n",
    "            \"P\": None,\n",
    "            \"Q\": None,\n",
    "            \"t\": None,\n",
    "            \"clusid\": None,\n",
    "        }\n",
    "    except IndexError as err:\n",
    "        raise Exception(f\"{smoothing=} {suffix=} {sign=} {model=}\") from err\n",
    "    else:\n",
    "        entries = {\n",
    "            \"C\": slm.P[\"pval\"][\"C\"],\n",
    "            \"P\": slm.P[\"pval\"][\"P\"],\n",
    "            \"Q\": slm.Q,\n",
    "            \"t\": slm.t,\n",
    "            \"clusid\": slm.P[\"clusid\"][0],\n",
    "        }\n",
    "    if entries[\"clusid\"] is not None:\n",
    "        entries[\"clusid\"] = entries[\"clusid\"][0]\n",
    "    for key, val in entries.items():\n",
    "        if val is None:\n",
    "            ds[key].data = np.full(ds[key].shape, np.nan)\n",
    "            continue\n",
    "        ds[key].data = val.reshape(ds[key].shape)\n",
    "    return ds\n",
    "\n",
    "\n",
    "import dask.array as da\n",
    "\n",
    "coords = {\n",
    "    \"smoothing\": hcp_smooth[\"smoothing\"].values[::2],\n",
    "    \"suffix\": [\"fw\", \"thickness\"],\n",
    "    \"model\": [\"group\"],\n",
    "}\n",
    "axes = {\"vertex\": 64984}\n",
    "variables = {\n",
    "    \"C\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"P\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"Q\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"t\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"clusid\": {\"dims\": [\"vertex\"], \"dtype\": int},\n",
    "}\n",
    "dims = list(coords.keys())\n",
    "comp_vars = {}\n",
    "for label, v in variables.items():\n",
    "    shape = tuple(len(x) for x in coords.values()) + tuple(axes[d] for d in v[\"dims\"])\n",
    "    chunks = (1,) * len(coords) + tuple(axes[d] for d in v[\"dims\"])\n",
    "\n",
    "    comp_vars[label] = xr.DataArray(\n",
    "        da.empty(shape=shape, chunks=chunks, dtype=v[\"dtype\"]),\n",
    "        dims=dims + v[\"dims\"],\n",
    "        coords=coords,\n",
    "    )\n",
    "template = xr.Dataset(comp_vars)\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "stats = xr.map_blocks(compute_stats, template, template=template)\n",
    "# stats.to_csv(\"stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "with dask.config.set(num_workers = 2):\n",
    "    with ProgressBar():\n",
    "        stats.load()\n",
    "stats.to_netcdf(\"hcp_rft.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Vertex-wise stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = xr.open_dataset(\"hcp_rft.nc\", chunks={})\n",
    "stats = stats.assign(\n",
    "    ma_t=stats[\"t\"].where(stats[\"C\"] < 0.05),\n",
    "    ma_clusid=stats[\"clusid\"].where(stats[\"C\"] < 0.05),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "result = []\n",
    "for suffix in [\"fw\", \"thickness\"]:\n",
    "    x = stats.sel(smoothing=5, suffix=suffix, model=\"group\")\n",
    "    clusids = np.unique(x[\"clusid\"])\n",
    "    for i in clusids:\n",
    "        vertices = np.nonzero(x[\"clusid\"].data == i)\n",
    "        if np.mean(x[\"C\"][vertices]) <= 0.05:\n",
    "            coords.append((suffix, i.astype(int)))\n",
    "            result.append(\n",
    "                hcp_smooth.sel(\n",
    "                    smoothing=5,\n",
    "                    desc=suffix,\n",
    "                )\n",
    "                .transpose(\"vertex\", ...)[vertices]\n",
    "                .mean(\"vertex\")\n",
    "            )\n",
    "\n",
    "clusters = (\n",
    "    xr.concat(result, dim=\"concat_dim\")\n",
    "    .assign_coords(dict(concat_dim=pd.Index(coords, name=(\"suffix\", \"clusid\"))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    clusters.to_dataframe(name=\"data\")\n",
    "    .drop(columns=[\"clusid\", \"suffix\"])\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .join(hcp.metadata, on=\"subject\", how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as scr\n",
    "\n",
    "\n",
    "def get_vertex_adjacency(lh, rh):\n",
    "    npoints = lh.GetNumberOfPoints() + rh.GetNumberOfPoints()\n",
    "    conns = []\n",
    "\n",
    "    for mesh, offset in zip((lh, rh), (0, lh.GetNumberOfPoints())):\n",
    "        for i in range(mesh.GetNumberOfCells()):\n",
    "            cell = mesh.GetCell(i)\n",
    "            ids = cell.GetPointIds() + offset\n",
    "            conns.extend(it.permutations(ids, 2))\n",
    "\n",
    "    row, col = np.array(conns).T\n",
    "    data = np.full_like(row, True, dtype=bool)\n",
    "    return scr.coo_matrix((data, (row, col)), shape=(npoints, npoints))\n",
    "\n",
    "\n",
    "mesh_adj = get_vertex_adjacency(lh, rh).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(arr, iter=5):\n",
    "    dilated = np.copy(arr)\n",
    "    for _ in range(iter):\n",
    "        for i in np.unique(dilated):\n",
    "            if np.isnan(i):\n",
    "                continue\n",
    "            indices = np.unique(np.argwhere(mesh_adj[dilated == i])[:, 1])\n",
    "            dilated[indices] = i\n",
    "    return dilated\n",
    "\n",
    "def smooth(arr):\n",
    "    smoothed = np.copy(arr)\n",
    "    for i in np.unique(smoothed):\n",
    "        if np.isnan(i):\n",
    "            continue\n",
    "        mask = np.argwhere(smoothed == i).ravel()\n",
    "        isolated = (np.sum(mesh_adj[np.ix_(mask, mask)], axis=0) < 4).getA1()\n",
    "        smoothed[mask[isolated]] = np.nan\n",
    "    return smoothed\n",
    "\n",
    "clus_arr = stats.sel(smoothing=5, suffix=\"fw\", model=\"group\")[\"ma_clusid\"].load().data\n",
    "dilated = smooth(dilate(clus_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lh = lh.n_points\n",
    "statmap = stats.sel(smoothing=5, suffix=\"fw\", model=\"group\")[\"ma_t\"].load().data\n",
    "lh.append_array(statmap[:n_lh], at=\"p\", name=\"t-val\")\n",
    "rh.append_array(statmap[n_lh:], at=\"p\", name=\"t-val\")\n",
    "lh.append_array(dilated[:n_lh], at=\"p\", name=\"outline\")\n",
    "rh.append_array(dilated[n_lh:], at=\"p\", name=\"outline\")\n",
    "fw_trange = np.nanmin(statmap), np.nanmax(statmap)\n",
    "fw_img = plot_surf(\n",
    "    {\n",
    "        \"lh\": lh,\n",
    "        \"rh\": rh,\n",
    "    },\n",
    "    [\n",
    "        [\"lh\", \"lh\",],\n",
    "        [ \"rh\", \"rh\"],\n",
    "    ],\n",
    "    # np.where(slm.t > 2, slm.t, np.nan),\n",
    "    # slm.t,\n",
    "    [\n",
    "        [ (None, \"outline\", \"t-val\")],\n",
    "        [(None, \"outline\", \"t-val\")],\n",
    "    ],\n",
    "    [\n",
    "        [(0, 60, 90), (-50, 100, 90)],\n",
    "        [(0, -70, -90), (-20, 130, 90)],\n",
    "    ],\n",
    "    color_bar=True,\n",
    "    cmap=[\n",
    "        [\n",
    "            (\"autumn\", cmaps.dark2_5,cmaps.matter_r),\n",
    "        ],\n",
    "        [\n",
    "            (\"autumn\", cmaps.dark2_5,cmaps.matter_r),\n",
    "        ],\n",
    "    ],\n",
    "    color_range=[\n",
    "        [(None, (1, 5), fw_trange)],\n",
    "        [(None, (1, 5), fw_trange)],\n",
    "    ],\n",
    "    embed_nb=True,\n",
    "    size=(700*3, 500*3),\n",
    "    zoom=1.85,\n",
    "    nan_color=(0.7, 0.7, 0.7, 0),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    transparent_bg=False,\n",
    "    return_plotter=True,\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lh = lh.n_points\n",
    "statmap = stats.sel(smoothing=5, suffix=\"thickness\", model=\"group\")[\"ma_t\"].load().data\n",
    "lh.append_array(statmap[:n_lh], at=\"p\", name=\"t-val\")\n",
    "rh.append_array(statmap[n_lh:], at=\"p\", name=\"t-val\")\n",
    "thi_trange = np.nanmin(statmap), np.nanmax(statmap)\n",
    "thickness_img = plot_surf(\n",
    "    {\n",
    "        \"lh\": lh,\n",
    "        \"rh\": rh,\n",
    "    },\n",
    "    [\n",
    "        [\"lh\", \"lh\", \"rh\", \"rh\"],\n",
    "    ],\n",
    "    # np.where(slm.t > 2, slm.t, np.nan),\n",
    "    # slm.t,\n",
    "    [\n",
    "        [(None, \"t-val\")],\n",
    "    ],\n",
    "    [\n",
    "        [\"lateral\", \"medial\", \"medial\", \"lateral\"],\n",
    "    ],\n",
    "    color_bar=True,\n",
    "    cmap=[\n",
    "        [(\"autumn\", cm.winter)],\n",
    "    ],\n",
    "    color_range=[\n",
    "        [(None, thi_trange)],\n",
    "    ],\n",
    "    embed_nb=True,\n",
    "    size=(2000 * 3, 400 * 3),\n",
    "    zoom=1.55,\n",
    "    nan_color=(0.7, 0.7, 0.7, 0),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    transparent_bg=False,\n",
    "    return_plotter=True,\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7.5), layout=\"constrained\")\n",
    "panela, panelb = fig.subfigures(2, 1, height_ratios=[6, 1.5])\n",
    "panela.text(0, 1, \"A\", va=\"top\", **Styles.panel_label)\n",
    "grid = panela.add_gridspec(3, 2)\n",
    "surf_panel = panela.add_subfigure(grid[0, 1])\n",
    "surf_axs = surf_panel.subplots(1, 2, width_ratios=[14, 1])\n",
    "surf_axs[0].imshow(fw_img)\n",
    "surf_axs[0].axis(\"off\")\n",
    "surf_axs[0].set_position(\n",
    "    surf_axs[0].get_position().translated(-0.03, -0.1).expanded(1.5, 1.5)\n",
    ")\n",
    "surf_axs[0].text(\n",
    "    -0.2, 0.75, \"Left\", **Styles.col_title, transform=surf_axs[0].transAxes\n",
    ")\n",
    "surf_axs[0].text(\n",
    "    -0.2, 0.25, \"Right\", **Styles.col_title, transform=surf_axs[0].transAxes\n",
    ")\n",
    "add_colorbar(*fw_trange, ax=surf_axs[1], cmap=cmaps.matter_r)\n",
    "surf_axs[1].set_ylabel(\"T-value\")\n",
    "surf_axs[1].set_position(surf_axs[1].get_position().translated(0, -0.1))\n",
    "\n",
    "clusids = df.filter(suffix=\"fw\")[\"clusid\"].unique()\n",
    "titles = [\n",
    "    \"L-Insula\",\n",
    "    \"R-Insula\",\n",
    "    \"L-Middle Temporal Gyrus\",\n",
    "    \"L-Occipital Lobe\",\n",
    "    \"R-Occipital Lobe\",\n",
    "]\n",
    "for i, pos in enumerate(np.array(list(grid))[[0, 2, 3, 4, 5]]):\n",
    "    ax = panela.add_subplot(pos)\n",
    "    comparison_plot(\n",
    "        df.filter(pl.col.suffix == \"fw\", clusid=clusids[i]),\n",
    "        x=\"group\",\n",
    "        y=\"data\",\n",
    "        alpha=0.7,\n",
    "        color=cmaps.dark2_5(i),\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(\"\" if i < 3 else \"Group\")\n",
    "    ax.set_ylabel(r\"$f_{fw}$\" if i in {0, 1, 3} else \"\")\n",
    "    ax.set_title(titles[i], fontsize=14)\n",
    "\n",
    "ax, cax = panelb.subplots(1, 2, width_ratios=[40, 1])\n",
    "panelb.text(0, 1.03, \"B\", **Styles.panel_label)\n",
    "ax.imshow(thickness_img)\n",
    "ax.axis(\"off\")\n",
    "ax.text(\n",
    "    -0.03, 0.5, \"Thickness\", **Styles.row_title, transform=ax.transAxes\n",
    ")\n",
    "add_colorbar(*thi_trange, ax=cax, cmap=\"winter\")\n",
    "cax.set_ylabel(\"T-value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-surf-rft\n",
    "---\n",
    "Cortical clusters significantly affected in patients. Clusters determined with random field theory with a P-value threshold of 0.01. One-tailed t-tests used for both parameters, testing increased $f_{fw}$ and decreased thickness.  A. Clusters with a significantly higher. Bar plot colors correspond with the outline colors on the surface illustrations, with titles clarifying the location. B. Clusters with significantly lower thickness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_modelling = BidsLayout(\"../HCPpsych/derivatives/noddi-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "@layout_map(\n",
    "    dims={\"src\": atlases.bn246[\"Label ID\"], \"dest\": atlases.bn246[\"Label ID\"]},\n",
    "    dtype=int,\n",
    ")\n",
    "def load_h5_nbs(file):\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        try:\n",
    "            networks = f[\"nbs/con_mat\"][:]\n",
    "            # sizes = np.sum(networks.reshape(-1, networks.shape[-1]), axis=0)\n",
    "            # labels = np.argsort(sizes)[::-1] + 1\n",
    "            # return np.sum(networks * labels, axis=-1)\n",
    "            sig = np.sum(networks, axis=-1)\n",
    "        except IndexError:\n",
    "            sig = 0\n",
    "        return f[\"nbs/test_stat\"][:] * sig\n",
    "\n",
    "\n",
    "descs = [\n",
    "    \"\".join(x)\n",
    "    for x in it.product([\"fw\", \"ndi\", \"odi\"], [\"phenotype\", \"panssp\", \"panssn\"])\n",
    "]\n",
    "hcp_nbs = load_h5_nbs(\n",
    "    hcp_modelling.get(suffix=\"nbs\", label=[\"pos\", \"neg\"], desc=descs), [\"desc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White matter ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wm_from_rois(path, wildcards, atlases):\n",
    "    labels = list(\n",
    "        it.chain.from_iterable(\n",
    "            zip(it.repeat(i), range(np.max(atlas).astype(int) + 1))\n",
    "            for i, atlas in enumerate(atlases)\n",
    "        )\n",
    "    )\n",
    "    nlabels = len(labels)\n",
    "\n",
    "    @layout_map(parallel=True, dims={\"roi\": nlabels}, dtype=float)\n",
    "    def inner(path):\n",
    "        data = nb.load(path).get_fdata()\n",
    "        result = np.empty((nlabels,))\n",
    "        try:\n",
    "            for i in range(0, nlabels):\n",
    "                atlas_ix, ix = labels[i]\n",
    "                if ix == 0:\n",
    "                    result[i] = 0\n",
    "                    continue\n",
    "                atlas = atlases[atlas_ix]\n",
    "\n",
    "                result[i] = np.mean(data[atlas == ix])\n",
    "            return result\n",
    "        except:\n",
    "            print(path)\n",
    "            raise\n",
    "\n",
    "    return inner(path, wildcards)\n",
    "\n",
    "\n",
    "atlas_md = pl.read_csv(\"atlas-study_labels.csv\")\n",
    "\n",
    "\n",
    "def get_group_mapping():\n",
    "    groups = atlas_md.filter(group=\"core\")\n",
    "    group_id, atlas_id = atlas_md.join(\n",
    "        groups[[\"name\"]], left_on=\"group\", right_on=\"name\"\n",
    "    ).with_columns(\n",
    "        pl.col.group.replace(\n",
    "            dict(zip(*groups[[\"name\", \"atlas_id\"]])), return_dtype=pl.Int32\n",
    "        )\n",
    "    )[[\"group\", \"atlas_id\"]]\n",
    "    mapping = np.zeros(((atlas_id.max() + 1),))\n",
    "    mapping[atlas_id] = group_id\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def get_atlases(layout, dims, jhu_atlas, lobe_atlas):\n",
    "    @layout_map(parallel=True, dims=dims, dtype=float)\n",
    "    def get_skeleton(path):\n",
    "        return nb.load(path).get_fdata()\n",
    "\n",
    "    mean_skeleton = get_skeleton(layout, [\"subject\"]).mean([\"subject\"]) > 0\n",
    "    jhu_atlas, lobe_atlas = (\n",
    "        np.where(mean_skeleton, nb.load(atlas).get_fdata(), 0)\n",
    "        for atlas in (jhu_atlas, lobe_atlas)\n",
    "    )\n",
    "    core_groups = get_group_mapping().astype(int)\n",
    "    lobe_mask = np.where(jhu_atlas == 0, lobe_atlas, 0)\n",
    "    return {\n",
    "        \"lobe_mask\": lobe_mask,\n",
    "        \"jhu_atlas\": jhu_atlas,\n",
    "        \"global_mask\": (jhu_atlas > 0) | (lobe_mask > 0),\n",
    "        \"core-periph\": (jhu_atlas > 0).astype(int) + ((lobe_mask > 0).astype(int)) * 2,\n",
    "        \"core_group_mask\": core_groups[jhu_atlas.astype(int)],\n",
    "    }\n",
    "\n",
    "\n",
    "def run_roi_sampling(layout, jhu_atlas, lobe_atlas, skeleton_dims):\n",
    "    atlases = get_atlases(\n",
    "        layout.get(suffix=\"skeletonized\", desc=\"ndi\"),\n",
    "        dims=skeleton_dims,\n",
    "        jhu_atlas=jhu_atlas,\n",
    "        lobe_atlas=lobe_atlas,\n",
    "    )\n",
    "    return get_wm_from_rois(\n",
    "        layout.get(suffix=\"skeletonized\", desc=[\"ndi\", \"fw\", \"odi\"]),\n",
    "        [\"subject\", \"desc\"],\n",
    "        atlases=[atlases[\"lobe_mask\"], atlases_]\n",
    "        # atlases=list(atlases.values()),\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_hemispheres(layout, atlas, skeleton_dims):\n",
    "    mean_skeleton = (\n",
    "        get_mean_skeleton(\n",
    "            layout.get(suffix=\"skeletonized\", desc=\"ndi\"),\n",
    "            [\"subject\"],\n",
    "            dims=skeleton_dims,\n",
    "        ).mean([\"subject\"])\n",
    "        > 0\n",
    "    )\n",
    "    atlas = np.where(mean_skeleton, nb.load(atlas).get_fdata(), 0)\n",
    "    atlas[(atlas < 7) & (atlas % 2 == 1)] = 1\n",
    "    atlas[(atlas % 2 == 0) & (atlas != 0)] = 2\n",
    "    atlas[atlas > 2] = 0\n",
    "    return get_wm_from_rois(\n",
    "        layout.get(suffix=\"skeletonized\", desc=[\"ndi\", \"fw\", \"odi\"]),\n",
    "        [\"subject\", \"desc\"],\n",
    "        atlases=[atlas],\n",
    "    )\n",
    "\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "hcp_wm_sampled = run_roi_sampling(\n",
    "    hcp.layout.get(suffix=\"skeletonized\", datatype=False),\n",
    "    jhu_atlas=\"../HCPpsych/derivatives/atlases/atlas.nii.gz\",\n",
    "    lobe_atlas=\"../HCPpsych/derivatives/atlases/lobe-atlas.nii.gz\",\n",
    "    skeleton_dims={\"x\": 121, \"y\": 145, \"z\": 121},\n",
    ")\n",
    "\n",
    "# hcp_hemi_sampled = sample_hemispheres(\n",
    "#     hcp.layout.get(suffix=\"skeletonized\", datatype=False),\n",
    "#     atlas=\"../HCPpsych/derivatives/atlases/hemi-atlas.nii.gz\",\n",
    "#     skeleton_dims={\"x\": 121, \"y\": 145, \"z\": 121},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_atlas = \"../HCPpsych/derivatives/atlases/atlas.nii.gz\"\n",
    "lobe_atlas = \"../HCPpsych/derivatives/atlases/lobe-atlas.nii.gz\"\n",
    "atlas = \"../HCPpsych/derivatives/atlases/hemi-atlas.nii.gz\"\n",
    "\n",
    "skeleton_dims = {\"x\": 121, \"y\": 145, \"z\": 121}\n",
    "atlases = get_atlases(\n",
    "    hcp.layout.get(suffix=\"skeletonized\", desc=\"ndi\"),\n",
    "    dims=skeleton_dims,\n",
    "    jhu_atlas=jhu_atlas,\n",
    "    lobe_atlas=lobe_atlas,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "bg = \"../HCPpsych/derivatives/tpl-FA/tpl-study/tpl-study_FA.nii.gz\"\n",
    "img = nb.load(bg)\n",
    "param_map = nb.Nifti1Image(\n",
    "    atlases[\"core_group_mask\"],\n",
    "    img.affine,\n",
    "    img.header,\n",
    ")\n",
    "plotting.plot_roi(\n",
    "    param_map,\n",
    "    bg,\n",
    "    cut_coords=np.r_[-10:50:7j],\n",
    "    resampling_interpolation=\"nearest\",\n",
    "    display_mode=\"z\",\n",
    "    annotate=False,\n",
    "    colorbar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ProgressBar():\n",
    "    hcp_wm_sampled.to_netcdf(\"hcp_wm_sampled.nc\")\n",
    "    # hcp_hemi_sampled.to_netcdf(\"hcp_hemi_sampled.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_hemi_sampled = xr.open_dataarray(\"hcp_hemi_sampled.nc\", chunks={}).drop_sel(\n",
    "    subject=\"1032\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_hemi_df = (\n",
    "    hcp_hemi_sampled.to_dataframe(name=\"data\")\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .with_columns(\n",
    "        pl.col.roi.replace(\n",
    "            {\n",
    "                1: \"L\",\n",
    "                2: \"R\",\n",
    "            },\n",
    "            return_dtype=pl.String,\n",
    "        )\n",
    "    )\n",
    "    .filter(pl.col.roi.is_in([\"L\", \"R\"]))\n",
    "    .join(hcp.metadata, on=\"subject\", how=\"inner\")\n",
    "    .pivot(\n",
    "        index=[\"subject\", \"roi\", \"group\", \"PANSSP\", \"PANSSN\", \"age\", \"sex\"],\n",
    "        columns=\"desc\",\n",
    "        values=\"data\",\n",
    "    )\n",
    ")\n",
    "\n",
    "lm = smf.mixedlm(\n",
    "    \"scale(ndi) ~ scale(age) + sex + group*roi\",\n",
    "    groups=\"subject\",\n",
    "    data=hcp_hemi_df.to_pandas(),\n",
    ").fit()\n",
    "print(lm.summary())\n",
    "lm = smf.ols(\n",
    "    \"scale(fw) ~ scale(age) + sex + group*roi\",\n",
    "    # groups=\"subject\",\n",
    "    data=hcp_hemi_df.to_pandas()\n",
    ").fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_wm_sampled = xr.open_dataarray(\"hcp_wm_sampled.nc\", chunks={}).drop_sel(\n",
    "    subject=\"1032\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_md = pl.read_csv(\"atlas-study_labels.csv\")\n",
    "\n",
    "atlas_filters = [\n",
    "    ~pl.col(\"label\").is_in(\n",
    "        [\n",
    "            \"Med\",\n",
    "            \"Po\",\n",
    "            \"Mb\",\n",
    "            \"FTS\",\n",
    "        ]\n",
    "    ),\n",
    "    pl.col(\"group\") != \"cerebellar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_indices = dict(\n",
    "    zip(*atlas_md.filter(pl.col(\"group\").is_in([\"core\", \"global\"]))[[\"name\", \"index\"]])\n",
    ")\n",
    "\n",
    "\n",
    "def get_index(group: str):\n",
    "    return pl.lit(group_indices[group], dtype=pl.Int64)\n",
    "\n",
    "\n",
    "def prepare_wm_rois(df, index):\n",
    "    df = df.join(atlas_md.rename({\"index\": \"roi\"}), on=\"roi\").filter(*atlas_filters)\n",
    "    return (\n",
    "        df.join(atlas_md.rename({\"index\": \"roi\"}), on=\"roi\")\n",
    "        .filter(*atlas_filters)\n",
    "        .group_by(*index, \"label\")\n",
    "        .agg(\n",
    "            pl.col(\n",
    "                \"region\",\n",
    "                \"hierarchy\",\n",
    "            ).first(),\n",
    "            pl.col(\"data\").mean(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sessions(da, hx):\n",
    "    return prepare_wm_rois(\n",
    "        da.to_dataset(name=\"data\")\n",
    "        .to_dataframe()\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "        .pipe(pl.from_pandas),\n",
    "        [\"subject\", \"desc\"],\n",
    "    ).join(hx[[\"subject\", \"group\", \"age\", \"sex\", \"PANSSN\", \"PANSSP\"]], on=[\"subject\"])\n",
    "\n",
    "\n",
    "hcp_wm_df = all_sessions(\n",
    "    hcp_wm_sampled,\n",
    "    hcp.metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wm_ols(col, filter=None):\n",
    "    if col == \"group\":\n",
    "        contr = \"group[T.Patient]\"\n",
    "    else:\n",
    "        contr = col\n",
    "    return ple.ols(\n",
    "        f\"data ~ {col} + age + sex\",\n",
    "        contr,\n",
    "        filter=filter,\n",
    "        columns=\"desc\",\n",
    "        alternative=pl.when(pl.col.desc == \"fw\").then(pl.lit(1)).otherwise(pl.lit(-1)),\n",
    "    ).alias(f\"{col}_stats\")\n",
    "\n",
    "\n",
    "def get_wm_stats(df):\n",
    "    return (\n",
    "        df.group_by(\"label\", \"desc\")\n",
    "        .agg(\n",
    "            get_wm_ols(\"group\"),\n",
    "            get_wm_ols(\"PANSSP\", pl.col.group == \"Patient\"),\n",
    "            get_wm_ols(\"PANSSN\", pl.col.group == \"Patient\"),\n",
    "            pl.first(\"hierarchy\"),\n",
    "        )\n",
    "        .melt([\"desc\", \"label\", \"hierarchy\"], cs.matches(\".*_stats\"), \"model\", \"stats\")\n",
    "        .with_columns(pl.col(\"model\").str.split(\"_\").list.first())\n",
    "        .unnest(\"stats\")\n",
    "        .with_columns(\n",
    "            pl.col(\"pval\")\n",
    "            .map_elements(\n",
    "                lambda x: pl.Series(scs.false_discovery_control(x)),\n",
    "                return_dtype=pl.List(pl.Float64),\n",
    "            )\n",
    "            .over(\"desc\", \"model\", \"hierarchy\")\n",
    "            .name.suffix(\"corr\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "hcp_wm_stats = get_wm_stats(hcp_wm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_wm_stats.filter(label=\"UNC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot WM changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colormaps.utils import concat as cmaps_concat\n",
    "\n",
    "plt.switch_backend(\"cairo\")\n",
    "\n",
    "side_title = dict(\n",
    "    x=-0.1,\n",
    "    y=0.5,\n",
    "    rotation=\"vertical\",\n",
    "    rotation_mode=\"anchor\",\n",
    "    size=10,\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    color=Styles.Colors.dark[0],\n",
    ")\n",
    "_df = hcp_wm_df.with_columns(\n",
    "    pl.col.label.replace(\n",
    "        {\"PWM\": \"Peripheral\", \"CWM\": \"Core\", \"UNC\": \"Uncinate Fasciculus\"}\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(7, 8), layout=\"constrained\")\n",
    "panelab, panelc = fig.subfigures(1, 2, width_ratios=[3, 4])\n",
    "\n",
    "panela, panelb = panelab.subfigures(2, 1, height_ratios=[3, 1])\n",
    "panela.text(0, 1, \"A\", va=\"top\", **Styles.panel_label)\n",
    "axs = panela.subplots(3, 1)\n",
    "params = [\"ndi\", \"odi\", \"fw\"]\n",
    "labels = {\n",
    "    \"fw\": \"$f_{fw}$\",\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"odi\": \"ODI\",\n",
    "    \"phenotype\": \"Phenotype\",\n",
    "    \"panssp\": \"PANSS30-P\",\n",
    "    \"panssn\": \"PANSS30-N\",\n",
    "}\n",
    "for i in range(3):\n",
    "    __df = _df.filter(pl.col.label.is_in([\"Peripheral\", \"Core\"]), desc=params[i])\n",
    "    ax = axs[i]\n",
    "    sns.stripplot(\n",
    "        __df,\n",
    "        y=\"data\",\n",
    "        x=\"label\",\n",
    "        hue=\"group\",\n",
    "        dodge=True,\n",
    "        legend=False,\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"Core\", \"Peripheral\"],\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.violinplot(\n",
    "        __df,\n",
    "        y=\"data\",\n",
    "        x=\"label\",\n",
    "        hue=\"group\",\n",
    "        split=True,\n",
    "        legend=False,\n",
    "        palette=([cm.tab10(0), cm.tab10(1)]),\n",
    "        alpha=0.4,\n",
    "        linecolor=\"#f0f0f0\",\n",
    "        linewidth=1,\n",
    "        inner=\"quart\",\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"Core\", \"Peripheral\"],\n",
    "        cut=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(\"\" if i < 2 else \"Tracts\")\n",
    "    ax.set_ylabel(labels[params[i]])\n",
    "add_legend(\n",
    "    panela,\n",
    "    [\"HC\", \"Patient\"],\n",
    "    cmap=cm.tab10,\n",
    "    fontsize=10,\n",
    "    loc=\"center right\",\n",
    "    bbox_to_anchor=(1.05, 0.47),\n",
    ")\n",
    "\n",
    "ax = panelb.subplots(1, 1)\n",
    "panelb.text(0.01, 0.98, \"B\", va=\"top\", **Styles.panel_label)\n",
    "__df = _df.filter(label=\"Uncinate Fasciculus\", desc=\"fw\")\n",
    "comparison_plot(\n",
    "    __df,\n",
    "    y=\"data\",\n",
    "    x=\"group\",\n",
    "    hue=\"group\",\n",
    "    order=[\"HC\", \"Patient\"],\n",
    "    hue_order=[\"HC\", \"Patient\"],\n",
    "    alpha=0.8,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Group\")\n",
    "ax.set_ylabel(labels[\"fw\"])\n",
    "ax.set_title(\"Uncinate Fasciculus\")\n",
    "annot = Annotator(\n",
    "    ax,\n",
    "    data=__df.to_pandas(),\n",
    "    x=\"group\",\n",
    "    y=\"data\",\n",
    "    pairs=[(\"HC\", \"Patient\")],\n",
    "    verbose=False,\n",
    ")\n",
    "_ = (\n",
    "    annot.configure(test=None)\n",
    "    .set_pvalues(\n",
    "        [hcp_wm_stats.filter(desc=\"fw\", label=\"UNC\", model=\"group\")[\"pvalcorr\"][0]]\n",
    "    )\n",
    "    .annotate()\n",
    ")\n",
    "panelb.set_facecolor(\"#e0e0e0\")\n",
    "\n",
    "\n",
    "main, gutter = panelc.subfigures(1, 2, width_ratios=[3.1, 0.9])\n",
    "panelc.text(0, 1, \"C\", va=\"top\", **Styles.panel_label)\n",
    "axs = main.subplots(3, 1)\n",
    "params = [\"ndi\", \"odi\", \"fw\"]\n",
    "cms = {1: cmaps.ember.cut(0.4, \"left\"), -1: cmaps.cosmic.cut(0.2, \"left\")}\n",
    "vcms = np.array([-1, -1, 1])\n",
    "max_edge = hcp_nbs.max()\n",
    "for y in range(3):\n",
    "    ax = axs[y]\n",
    "    ax.axis(\"off\")\n",
    "    plot_hierachical_connectome(\n",
    "        hcp_nbs.sel(desc=f\"{params[y]}phenotype\"),\n",
    "        nodes=atlases.bn246,\n",
    "        ax=ax,\n",
    "        emin=3,\n",
    "        emax=max_edge,\n",
    "        # ecmap=cmaps.vivid,\n",
    "        ecmap=cms[vcms[y]],\n",
    "        vcmap=cmaps_concat([cmaps.gray_5.cut(0.4, \"right\")] * 4).discrete(8),\n",
    "        hierarchy=[\"Gyrus\", \"hemisphere\"],\n",
    "    )\n",
    "    ax.set_title(\n",
    "        labels[params[y]], **(side_title | {\"size\": 12, \"x\": -0.02, \"va\": \"bottom\"})\n",
    "    )\n",
    "    if y == 0:\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            1.1,\n",
    "            labels[\"phenotype\"],\n",
    "            color=Styles.Colors.dark[0],\n",
    "            size=10,\n",
    "            ha=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "        )\n",
    "\n",
    "grid = gutter.add_gridspec(6, 1)\n",
    "cbar1 = gutter.add_subplot(grid[3:5])\n",
    "add_colorbar(3, max_edge, cms[1], cbar1, outline=False)\n",
    "cbar1.set_ylabel(\"T-value\", size=10, color=Styles.Colors.dark[0])\n",
    "cbar1.set_title(\n",
    "    \"Positive correlations\",\n",
    "    **side_title,\n",
    ")\n",
    "cbar1.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "\n",
    "cbar2 = gutter.add_subplot(grid[1:3])\n",
    "add_colorbar(3, max_edge, cms[-1], cbar2, outline=False)\n",
    "cbar2.set_ylabel(\"T-value\", size=10, color=Styles.Colors.dark[0])\n",
    "cbar2.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "cbar2.set_title(\n",
    "    \"Negative correlations\",\n",
    "    **side_title,\n",
    ")\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "buf = BytesIO()\n",
    "fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "Image(buf.getbuffer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-wm\n",
    "---\n",
    "Effect of diagnosis plays limited role in white matter. A. Diagnosis does not significantly affect global NDI, ODI, or $f_{fw}$. B. Bilaterally averaged uncinate fasciculus has significantly higher $f_{fw}$ in patients ($T(106)=3.1;P=.02$), corrected for multiple comparisons across JHU atlas ROIs using FDR. C. Connections significantly affected by diagnosis as determined by NBS (10,000 iterations, T-thresh=3, FWER=0.05)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
