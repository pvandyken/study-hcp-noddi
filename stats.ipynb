{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsbids import BidsLayout\n",
    "import ciftipy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainspace.plotting import plot_hemispheres\n",
    "from brainspace.mesh.mesh_io import read_surface\n",
    "from brainstat.datasets import fetch_template_surface, fetch_mask\n",
    "from lib.mesh import mesh_smooth\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import itertools as it\n",
    "import xarray as xr\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from lib.bidsarray import layout_map\n",
    "from lib.plotting import move_legend_fig_to_ax\n",
    "from pathlib import Path\n",
    "from matplotlib import font_manager\n",
    "import templateflow.api as tflow\n",
    "\n",
    "from styles import styles as Styles\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.style.use(\"styles/presentation.mplstyle\")\n",
    "font_dirs = [Path.home() / \".fonts\"]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout = BidsLayout(\n",
    "#     [\"../../derivatives/surfsample-0.1.0/\", \"../../derivatives/snakeanat-diffusion-v0.0.1/\"],\n",
    "#     cache=\".cache\",\n",
    "#     reset_cache=True,\n",
    "# )\n",
    "layout = BidsLayout.load(\".cache\")\n",
    "lh, rh = fetch_template_surface(\"fslr32k\", layer=\"inflated\", join=False)\n",
    "mesh = fetch_template_surface(\"fslr32k\", layer=\"inflated\")\n",
    "mask = fetch_mask(\"fslr32k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the surface sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = set(layout.entities[\"subject\"]) - {\"001\", \"003\"}\n",
    "md = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\"panss-pre.csv\").assign(session=\"pre\"),\n",
    "        pd.read_csv(\"panss-post.csv\").assign(session=\"post\"),\n",
    "    ]\n",
    ").assign(subject=lambda df: df[\"participant_id\"].map(lambda s: s[3:]))[\n",
    "    lambda df: df[\"subject\"].isin(sub_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_hems(img):\n",
    "    l = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project(0).flatten()\n",
    "    r = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project(0).flatten()\n",
    "    return l, r\n",
    "\n",
    "\n",
    "def load_data(layout):\n",
    "    wcards = [wcard for wcard, vals in layout.entities.items() if len(vals) > 1]\n",
    "    md = []\n",
    "\n",
    "    idx = {\n",
    "        wcard: dict(map(reversed, enumerate(layout.entities[wcard])))\n",
    "        for wcard in wcards\n",
    "    }\n",
    "    counts = [len(layout.entities[wcard]) for wcard in wcards]\n",
    "\n",
    "    data = None\n",
    "    for path in tqdm.tqdm(layout):\n",
    "        loc = [idx[wcard][path.entities[wcard]] for wcard in wcards]\n",
    "        md.append(path.entities)\n",
    "        img = cp.load(path)\n",
    "        lh, rh = get_hems(img)\n",
    "        if data is None:\n",
    "            data = np.full((*counts, lh.shape[0] + rh.shape[0]), np.NaN)\n",
    "            bound = lh.shape[0]\n",
    "        data[(*loc, slice(None, bound))] = lh\n",
    "        data[(*loc, slice(bound, None))] = rh\n",
    "\n",
    "    coords = {\n",
    "        wcard: [t[0] for t in sorted(idx[wcard].items(), key=lambda t: t[1])]\n",
    "        for wcard in wcards\n",
    "    }\n",
    "    return xr.DataArray(data, dims=(*wcards, \"vertex\"), coords=coords)\n",
    "\n",
    "\n",
    "ds = (\n",
    "    xr.concat(\n",
    "        [\n",
    "            load_data(\n",
    "                layout.get(\n",
    "                    desc=[\"odi\", \"ndi\", \"fw\"],\n",
    "                    sub=sub_list,\n",
    "                )\n",
    "            ),\n",
    "            load_data(\n",
    "                layout.get(\n",
    "                    desc=[\"FA\", \"MD\", \"L1\", \"RD\"],\n",
    "                    sub=sub_list,\n",
    "                )\n",
    "            ),\n",
    "            load_data(\n",
    "                layout.get(\n",
    "                    suffix=\"thickness\",\n",
    "                    den=\"32k\",\n",
    "                    sub=sub_list,\n",
    "                )\n",
    "            ).expand_dims(desc=[\"thickness\"]),\n",
    "        ],\n",
    "        dim=\"desc\",\n",
    "    )\n",
    "    .to_dataset(name=\"surface\")\n",
    "    .merge(md.set_index([\"subject\", \"session\"]).to_xarray())\n",
    "    .drop_sel(subject=[\"005\", \"012\", \"026\", \"037\", \"044\", \"047\"])\n",
    ")\n",
    "ds.to_netcdf(\"checkpoint2.h5\")\n",
    "ds[\"surface_smooth\"] = xr.concat(\n",
    "    [\n",
    "        mesh_smooth(\n",
    "            ds[\"surface\"].where(mask),\n",
    "            surf=mesh,\n",
    "            FWHM=smoothing,\n",
    "            mask=mask,\n",
    "            axis=\"vertex\",\n",
    "\n",
    "        ).expand_dims(smoothing=[smoothing])\n",
    "        for smoothing in np.r_[5:15]\n",
    "    ],\n",
    "    dim=\"smoothing\"\n",
    ")\n",
    "ds.to_netcdf(\"surface_data.2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"surface_data.2.nc\", chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_smooth = ds.sel(smoothing=6)[\"surface_smooth\"]\n",
    "dkmd = pd.read_csv(\"atlas-dkt_labels.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "@layout_map(dims={\"param\": ds[\"desc\"].rename(desc=\"param\"), \"roi\": dkmd[\"label\"]})\n",
    "def sample_dk(path):\n",
    "    dknii = cp.load(path)\n",
    "    dkatlas = np.empty(32492 * 2)\n",
    "    dkatlas[:32492] = (\n",
    "        dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project().ravel()\n",
    "    )\n",
    "    dkatlas[32492:] = (\n",
    "        dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project().ravel()\n",
    "    )\n",
    "    result = np.empty((len(ds[\"desc\"]), len(dkmd)))\n",
    "    x = surf_smooth.sel(\n",
    "        subject=path.entities[\"subject\"], session=path.entities[\"session\"]\n",
    "    )\n",
    "    for (i, param), (j, label) in it.product(\n",
    "        enumerate(ds[\"desc\"]), enumerate(dkmd[\"label\"])\n",
    "    ):\n",
    "        result[i, j] = np.mean(x.sel(desc=param)[dkatlas == label])\n",
    "    return result\n",
    "\n",
    "\n",
    "dk_sample = (\n",
    "    sample_dk(\n",
    "        layout.get(\n",
    "            suffix=\"dparc\",\n",
    "            subject=ds[\"subject\"].data,\n",
    "            atlas=\"dkt\",\n",
    "            space=\"fsLR\",\n",
    "            den=\"32k\",\n",
    "        ),\n",
    "        wildcards=[\"subject\", \"session\"],\n",
    "    )\n",
    "    .to_dataset(name=\"dk\")\n",
    "    .merge(dkmd.rename(columns={\"label\": \"roi\"}).set_index(\"roi\").to_xarray())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_sample = xr.load_dataset(\"dk_sample.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as scs\n",
    "scs.zscore((\n",
    "    ds.sel(desc=\"RD\",  session=\"post\", smoothing=6)[\"surface\"] - \n",
    "    ds.sel(desc=\"RD\",  session=\"pre\", smoothing=6)[\"surface\"]\n",
    ").pipe(np.abs).mean(\"vertex\").to_dataframe()[\"surface\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hemispheres(\n",
    "    lh,\n",
    "    rh,\n",
    "    (\n",
    "        ds.sel(desc=\"FA\",  session=\"post\", smoothing=6)[\"surface\"]\n",
    "        .load()\n",
    "        .data -\n",
    "        ds.sel(desc=\"FA\",  session=\"pre\", smoothing=6)[\"surface\"]\n",
    "        .load()\n",
    "        .data\n",
    "    ),\n",
    "    color_bar=True,\n",
    "    color_range=(-0.5,0.5),\n",
    "    label_text=list(ds[\"subject\"].data),\n",
    "    cmap=\"coolwarm\",\n",
    "    embed_nb=True,\n",
    "    size=(1400, 5000),\n",
    "    zoom=1.45,\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    interactive=False,\n",
    "    background=(1, 1, 1),\n",
    "    transparent_bg=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "from brainstat.stats.terms import FixedEffect, MixedEffect\n",
    "from brainstat.stats.SLM import SLM\n",
    "ds_ = ds.sel(session=[\"post\"])#.drop_sel(subject=[\"008\", \"029\"])\n",
    "surface = (\n",
    "    ds_[\"surface_smooth\"]\n",
    "    .stack(obs=(\"subject\", \"session\"))\n",
    "    .transpose(\"desc\", \"smoothing\", \"obs\", \"vertex\")\n",
    ")\n",
    "df = (ds_[\"PANSS-N\"] / ds_[\"PANNS-P\"]).to_dataframe(name=\"panss-ratio\").reset_index()\n",
    "term_ses = FixedEffect(df[\"session\"])\n",
    "term_sub = MixedEffect(df[\"subject\"])\n",
    "ses_post = (df[\"session\"] == \"post\").astype(int)\n",
    "ses_pre = (df[\"session\"] == \"pre\").astype(int)\n",
    "term_panss = FixedEffect(df[\"panss-ratio\"])\n",
    "\n",
    "ses = {\n",
    "    \"model\": term_ses + term_sub,\n",
    "    \"contrast\": ses_post - ses_pre,\n",
    "    \"label\": \"ses\",\n",
    "}\n",
    "interact = {\n",
    "    \"model\": term_ses * term_panss + term_sub,\n",
    "    \"contrast\": (ses_post * df[\"panss-ratio\"]) - (ses_pre * df[\"panss-ratio\"]),\n",
    "    \"label\": \"intr\",\n",
    "}\n",
    "panss = {\n",
    "    \"model\": term_panss,\n",
    "    \"contrast\": df[\"panss-ratio\"] * -1,\n",
    "    \"label\": \"panss\",\n",
    "}\n",
    "slm = SLM(\n",
    "    panss[\"model\"],\n",
    "    panss[\"contrast\"],\n",
    "    mask=mask,\n",
    "    surf=\"fslr32k\",\n",
    "    correction=[\"rft\", \"fdr\"],\n",
    "    cluster_threshold=0.01,\n",
    "    two_tailed=False,\n",
    ")\n",
    "slm.fit(np.asanyarray(surface.sel(desc=\"FA\", smoothing=7)))\n",
    "cluster_p = [*(np.copy(slm.P[\"pval\"][idx]).T for idx in [\"C\", \"P\"]), np.copy(slm.Q)]\n",
    "for clust in cluster_p:\n",
    "    np.place(clust, np.logical_or(clust > 0.05, ~mask), np.nan)\n",
    "    np.copyto(clust, slm.t[0], where=~np.isnan(clust))\n",
    "\n",
    "\n",
    "plot_hemispheres(\n",
    "    lh,\n",
    "    rh,\n",
    "    np.vstack(cluster_p),\n",
    "    color_bar=True,\n",
    "    # label_text=[\"Cluster p-values\", \"Peak p-values\", \"Vertex p-values\"], cmap=\"autumn_r\",\n",
    "    cmap=\"autumn_r\",\n",
    "    embed_nb=True,\n",
    "    size=(1400, 800),\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    interactive=False,\n",
    "    transparent_bg=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "from brainstat.stats.terms import FixedEffect, MixedEffect\n",
    "from brainstat.stats.SLM import SLM\n",
    "\n",
    "surface = (\n",
    "    ds[\"surface_smooth\"]\n",
    "    .stack(obs=(\"subject\", \"session\"))\n",
    "    .transpose(\"desc\", \"smoothing\", \"obs\", \"vertex\")\n",
    ")\n",
    "\n",
    "df = ds[[\"PANSS-N\", \"PANNS-P\"]].to_dataframe().reset_index()\n",
    "panss_var = \"PANNS-P\"\n",
    "term_ses = FixedEffect(df[\"session\"])\n",
    "term_sub = MixedEffect(df[\"subject\"])\n",
    "ses_post = (df[\"session\"] == \"post\").astype(int)\n",
    "ses_pre = (df[\"session\"] == \"pre\").astype(int)\n",
    "term_panss = FixedEffect(df[panss_var])\n",
    "\n",
    "models = {\n",
    "    \"panss\": {\n",
    "        \"model\": term_ses * term_panss + term_sub,\n",
    "        \"contrast\": df[panss_var],\n",
    "        \"label\": \"panss\",\n",
    "    },\n",
    "    \"intr\": {\n",
    "        \"model\": term_ses * term_panss + term_sub,\n",
    "        \"contrast\": (ses_post * df[panss_var]) - (ses_pre * df[panss_var]),\n",
    "        \"label\": \"intr\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def compute_stats(ds):\n",
    "    smoothing = ds[\"smoothing\"].item()\n",
    "    suffix = ds[\"suffix\"].item()\n",
    "    sign = ds[\"sign\"].item()\n",
    "    model = models[ds[\"model\"].item()]\n",
    "    slm = SLM(\n",
    "        model[\"model\"],\n",
    "        model[\"contrast\"] * sign,\n",
    "        mask=mask,\n",
    "        surf=\"fslr32k\",\n",
    "        correction=[\"rft\", \"fdr\"],\n",
    "        cluster_threshold=0.01,\n",
    "        two_tailed=True,\n",
    "    )\n",
    "    try:\n",
    "        slm.fit(np.asanyarray(surface.sel(desc=suffix, smoothing=smoothing)))\n",
    "    except np.linalg.LinAlgError:\n",
    "        entries = {\n",
    "            \"C\": None,\n",
    "            \"P\": None,\n",
    "            \"Q\": None,\n",
    "            \"t\": None,\n",
    "            \"clusid\": None,\n",
    "        }\n",
    "    except IndexError as err:\n",
    "        raise Exception(f\"{smoothing=} {suffix=} {sign=} {model=}\") from err\n",
    "    else:\n",
    "        entries = {\n",
    "            \"C\": slm.P[\"pval\"][\"C\"],\n",
    "            \"P\": slm.P[\"pval\"][\"P\"],\n",
    "            \"Q\": slm.Q,\n",
    "            \"t\": slm.t,\n",
    "            \"clusid\": slm.P[\"clusid\"][0],\n",
    "        }\n",
    "    if entries[\"clusid\"] is not None:\n",
    "        entries[\"clusid\"] = entries[\"clusid\"][0]\n",
    "    for key, val in entries.items():\n",
    "        if val is None:\n",
    "            ds[key].data = np.full(ds[key].shape, np.nan)\n",
    "            continue\n",
    "        ds[key].data = val.reshape(ds[key].shape)\n",
    "    # for l, clust in zip((\"C\", \"P\", \"Q\"), cluster_p):\n",
    "    #     ds[l][:] = clust\n",
    "        # if not clust.shape and clust.item() is None:\n",
    "        #     ds[l][:] = np.nan\n",
    "        # np.place(clust, np.logical_or(clust > 0.05, ~mask), np.nan)\n",
    "        # np.copyto(clust, slm.t[0], where=~np.isnan(clust))\n",
    "        # ds[l][:] = np.sum(~np.isnan(clust))\n",
    "        # if np.any(np.isinf(stats[l]) | np.isnan(stats[l])):\n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "import dask.array as da\n",
    "coords = {\n",
    "    \"smoothing\": [7],#surface[\"smoothing\"].values[::2], \n",
    "    \"suffix\": [\"ndi\", \"odi\", \"fw\", \"thickness\"],#surface[\"desc\"].values,\n",
    "    \"sign\": [1, -1],\n",
    "    \"model\": [\"panss\", \"intr\"],\n",
    "}\n",
    "axes = {\n",
    "    \"vertex\": 64984\n",
    "}\n",
    "variables = {\n",
    "    \"C\": {\n",
    "        \"dims\": [\"vertex\"],\n",
    "        \"dtype\": float\n",
    "    },\n",
    "    \"P\": {\n",
    "        \"dims\": [\"vertex\"],\n",
    "        \"dtype\": float\n",
    "    },\n",
    "    \"Q\": {\n",
    "        \"dims\": [\"vertex\"],\n",
    "        \"dtype\": float\n",
    "    },\n",
    "    \"t\": {\n",
    "        \"dims\": [\"vertex\"],\n",
    "        \"dtype\": float\n",
    "    },\n",
    "    \"clusid\": {\n",
    "        \"dims\": [\"vertex\"],\n",
    "        \"dtype\": int\n",
    "    }\n",
    "    \n",
    "}\n",
    "dims = list(coords.keys())\n",
    "comp_vars = {}\n",
    "for label, v in variables.items():\n",
    "    shape = tuple(len(x) for x in coords.values()) + tuple(axes[d] for d in v[\"dims\"])\n",
    "    chunks = (1,) * len(coords) + tuple(axes[d] for d in v[\"dims\"])\n",
    "\n",
    "    comp_vars[label] = xr.DataArray(\n",
    "        da.empty(shape=shape, chunks=chunks, dtype=v[\"dtype\"]),\n",
    "        dims=dims + v[\"dims\"],\n",
    "        coords=coords\n",
    "    )\n",
    "template = xr.Dataset(comp_vars)\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "stats = xr.map_blocks(compute_stats, template, template=template)\n",
    "# stats.to_csv(\"stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dask.config.set(scheduler='processes', num_workers=4):\n",
    "with ProgressBar():\n",
    "    stats.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_netcdf(\"panssp-stats.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = xr.load_dataset(\"stats.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (stats[[\"Q\", \"C\", \"P\"]] < 0.05).sum(\"vertex\").to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"C\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix=\"FA\"\n",
    "# for l, clust in zip((\"C\", \"P\", \"Q\"), cluster_p):\n",
    "#     if not clust.shape and clust.item() is None:\n",
    "#         continue\n",
    "#     np.place(clust, np.logical_or(clust > 0.05, ~mask), np.nan)\n",
    "#     np.copyto(clust, slm.t[0], where=~np.isnan(clust))\n",
    "#     print(l, \"=\", np.sum(~np.isnan(clust)))\n",
    "\n",
    "\n",
    "def do_plot(data):\n",
    "    plot_hemispheres(\n",
    "        lh,\n",
    "        rh,\n",
    "        # np.where(slm.t > 2, slm.t, np.nan),\n",
    "        # slm.t,\n",
    "        data,\n",
    "        color_bar=True,\n",
    "        # label_text=[\"ndi\"],\n",
    "        cmap=\"viridis\",\n",
    "        embed_nb=True,\n",
    "        size=(1400, 1600),\n",
    "        zoom=1.45,\n",
    "        nan_color=(0.7, 0.7, 0.7, 1),\n",
    "        cb__labelTextProperty={\"fontSize\": 12},\n",
    "        transparent_bg=False,\n",
    "    )\n",
    "\n",
    "\n",
    "do_plot(\n",
    "    np.vstack(\n",
    "        [\n",
    "            stats.sel(smoothing=smoothing, suffix=\"ndi\", sign=-1, model=\"intr\")[\"C\"]\n",
    "            .where(lambda da: da < 0.05)\n",
    "            .data\n",
    "            for smoothing in range(5, 15)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hemispheres(\n",
    "    lh,\n",
    "    rh,\n",
    "    # np.where(slm.t > 2, slm.t, np.nan),\n",
    "    # slm.t,\n",
    "    stats.sel(\n",
    "        model=\"panss\", suffix=[\"ndi\", \"odi\", \"fw\", \"thickness\"], sign=-1, smoothing=5)[\"C\"]\n",
    "    .where(lambda da: da < 0.05)\n",
    "    .data,\n",
    "    color_bar=True,\n",
    "    # label_text=[\"ndi\"],\n",
    "    label_text=[\"NDI\", \"ODI\", \"$f_{FW}$\", \"Thickness\"],\n",
    "    cmap=\"viridis\",\n",
    "    embed_nb=True,\n",
    "    size=(1400, 200 * 4),\n",
    "    zoom=1.45,\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    transparent_bg=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "result = []\n",
    "for suffix, sign in [\n",
    "    (\"ndi\", -1),\n",
    "    (\"odi\", -1),\n",
    "    (\"fw\", 1),\n",
    "    (\"thickness\", -1),\n",
    "]:\n",
    "    x = stats.sel(smoothing=5, suffix=suffix, sign=sign, model=\"panss\")\n",
    "    clusids = np.unique(x[\"clusid\"])\n",
    "    for i in clusids:\n",
    "        vertices = np.nonzero(x[\"clusid\"].data == i)\n",
    "        if np.mean(x[\"C\"][vertices]) <= 0.05:\n",
    "            coords.append((suffix, i.astype(int)))\n",
    "            result.append(\n",
    "                ds.sel(\n",
    "                    smoothing=6,\n",
    "                    desc=suffix,\n",
    "                )[\"surface\"]\n",
    "                .transpose(\"vertex\", ...)[vertices]\n",
    "                .mean(\"vertex\")\n",
    "            )\n",
    "\n",
    "clusters = xr.concat(result, dim=pd.Index(coords, name=(\"param\", \"clusid\"))).chunk(\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusids = stats.sel(smoothing=5, suffix=\"fw\", sign=1, model=\"panss\")[\"clusid\"].where(\n",
    "    lambda da: ((da > 0) & (da < 4))\n",
    ")\n",
    "from nilearn import plotting, datasets\n",
    "\n",
    "lhem, rhem = tflow.get(template=\"fsLR\", density=\"32k\", suffix=\"inflated\")\n",
    "plotting.view_surf(\n",
    "    str(rhem),\n",
    "    clusids[clusids.shape[0] // 2 :].data,\n",
    "    # hemi=\"right\",\n",
    "    cmap=\"tab10\",\n",
    "    vmax=10,\n",
    "    vmin=1,\n",
    "    symmetric_cmap=False,\n",
    ").resize(1500, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "df = clusters.to_dataframe().drop(columns=[\"clusid\", \"param\"]).reset_index()\n",
    "df = (\n",
    "    df.set_index([\"subject\", \"session\"])\n",
    "    .join(\n",
    "        md[[\"PANNS-P\", \"subject\", \"session\"]].set_index([\"subject\", \"session\"]),\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df\n",
    "# result = smf.mixedlm(\"surface ~ session\", df, groups=df[\"subject\"]).fit()\n",
    "# result.summary()\n",
    "df[df[\"desc\"].isin([param])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "rois = {\n",
    "    \"frontal\": \"Frontal Lobe\",\n",
    "    \"parietal\": \"Parietal Lobe\",\n",
    "    \"occipital\": \"Occipital Lobe\",\n",
    "    \"temporal\": \"Temporal Lobe\",\n",
    "    \"cingulate\": \"Cingulate Gyrus\",\n",
    "    \"insula\": \"Insula\",\n",
    "}\n",
    "titles = {\n",
    "    \"FA\": \"FA\",\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"odi\": \"ODI\",\n",
    "    \"fw\": r\"$f_{fw}$\",\n",
    "    \"thickness\": \"Thickness\",\n",
    "    \"panss_n\": \"PANSS30-N\",\n",
    "    \"PANNS-P\": \"PANSS30-P\",\n",
    "}\n",
    "# for score, param in it.product(\n",
    "#     [\"panss_p\", \"panss_n\"], [\"odi\", \"ndi\", \"fw\", \"thickness\"]\n",
    "# ):\n",
    "score=\"PANNS-P\"\n",
    "param=\"ndi\"\n",
    "ses_order = so.Nominal(order=[\"post\", \"pre\"])\n",
    "(\n",
    "    so.Plot(\n",
    "        df[df[\"desc\"].isin([param])],\n",
    "        x=score,\n",
    "        y=\"surface\",\n",
    "        group=\"session\",\n",
    "        color=\"clusid\",\n",
    "    )\n",
    "    .facet(col=\"clusid\", wrap=2)\n",
    "    .add(so.Dot(color=\"#666666\"), fill=\"session\", marker=\"session\", legend=False)\n",
    "    .add(\n",
    "        so.Line(linewidth=3), so.PolyFit(order=1), linestyle=\"session\", legend=False\n",
    "    )\n",
    "    .layout(size=(10, 10))\n",
    "    .scale(linestyle=ses_order, marker=ses_order, fill=ses_order, color=\"tab10\")\n",
    "    .label(x=titles[score], y=titles[param], title=\"\")\n",
    "    .theme(plt.rcParams)\n",
    "    .save(f\"~/tsclient/khangrp4/Downloads/{score}-{param}-rft.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIS_L = np.array([\n",
    "    2, 3, 8, 9, 10, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35\n",
    "])\n",
    "ROIS = np.hstack([ROIS_L, ROIS_L + 35])\n",
    "ROIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscores = xr.apply_ufunc(\n",
    "    scs.zscore,\n",
    "    dk_sample[\"dk\"].sel(param=\"FA\").diff(\"session\").pipe(np.abs),\n",
    "    input_core_dims=[[\"subject\"]],\n",
    "    output_core_dims=[[\"subject\"]],\n",
    "    vectorize=True,\n",
    ").pipe(np.abs)\n",
    "outliers = zscores.max(\"roi\").where(lambda da: da > 3, drop=True)[\"subject\"].data\n",
    "dk_sample[\"dk\"].sel(param=\"FA\").diff(\"session\").pipe(np.abs).stack(\n",
    "    subroi=(\"subject\", \"roi\")\n",
    ").sel(\n",
    "    subroi=zscores.sel(subject=outliers)\n",
    "    .where(lambda da: da > 3, drop=True)\n",
    "    .stack(subroi=(\"subject\", \"roi\"))\n",
    "    .dropna(\"subroi\")[\"subroi\"]\n",
    ").where(\n",
    "    lambda da: da > 0.05, drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_grouped = dk_sample.groupby(\"lobe\").mean(\"roi\")\n",
    "# result = np.empty(len(hemi_grouped[\"name\"]))\n",
    "result = []\n",
    "# for i, name in enumerate(hemi_grouped[\"name\"]):\n",
    "df = (\n",
    "    ds[[\"PANSS-N\", \"PANNS-P\"]]\n",
    "    .rename({\"PANSS-N\": \"panss_n\", \"PANNS-P\": \"panss_p\"})\n",
    "    .assign(panss_ratio=lambda ds: ds[\"panss_n\"] / ds[\"panss_p\"])\n",
    "    .merge(hemi_grouped)\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    ")\n",
    "df.to_csv(\"sampled-dk-grouped-lobe.csv\")\n",
    "# lm1 = smf.mixedlm(\"dk ~ session*panss_ratio\", data=df, groups=\"subject\").fit()\n",
    "# lm2 = smf.mixedlm(\"dk ~ session+panss_ratio\", data=df, groups=\"subject\").fit()\n",
    "# lm2.random_effects_cov\n",
    "#     result.append(lm.pvalues)\n",
    "# result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "rois = {\n",
    "    \"frontal\": \"Frontal Lobe\",\n",
    "    \"parietal\": \"Parietal Lobe\",\n",
    "    \"occipital\": \"Occipital Lobe\",\n",
    "    \"temporal\": \"Temporal Lobe\",\n",
    "    \"cingulate\": \"Cingulate Gyrus\",\n",
    "    \"insula\": \"Insula\",\n",
    "}\n",
    "titles = {\n",
    "    \"FA\": \"FA\",\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"odi\": \"ODI\",\n",
    "    \"fw\": r\"$f_{fw}$\",\n",
    "    \"thickness\": \"Thickness\",\n",
    "}\n",
    "\n",
    "for param in (\n",
    "     [\"odi\", \"ndi\", \"fw\", \"thickness\"]\n",
    "):\n",
    "    (\n",
    "        so.Plot(\n",
    "            df[df[\"param\"].isin([param])],\n",
    "            x=\"session\",\n",
    "            y=\"dk\",\n",
    "            group=\"subject\",\n",
    "            color=\"lobe\",\n",
    "        )\n",
    "        .facet(col=\"lobe\",  wrap=2, order=list(rois))\n",
    "        .add(so.Dot(fill=None), legend=False)\n",
    "        .add(so.Line(linewidth=5), so.PolyFit(order=1), group=None, legend=False)\n",
    "        .add(so.Line(linestyle=\"dashed\", alpha=0.3), legend=False)\n",
    "        .layout(size=(10, 10))\n",
    "        .scale(x=so.Nominal(order=[\"pre\", \"post\"]))\n",
    "        .label(x=\"Session\", y=titles[param])\n",
    "        .theme(plt.rcParams)\n",
    "        .label(title=rois.get)\n",
    "        .save(f\"~/tsclient/khangrp4/Downloads/session-{param}.png\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "rois = {\n",
    "    \"frontal\": \"Frontal Lobe\",\n",
    "    \"parietal\": \"Parietal Lobe\",\n",
    "    \"occipital\": \"Occipital Lobe\",\n",
    "    \"temporal\": \"Temporal Lobe\",\n",
    "    \"cingulate\": \"Cingulate Gyrus\",\n",
    "    \"insula\": \"Insula\",\n",
    "}\n",
    "titles = {\n",
    "    \"FA\": \"FA\",\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"odi\": \"ODI\",\n",
    "    \"fw\": r\"$f_{fw}$\",\n",
    "    \"thickness\": \"Thickness\",\n",
    "    \"panss_n\": \"PANSS30-N\",\n",
    "    \"panss_p\": \"PANSS30-P\",\n",
    "}\n",
    "ses_order = so.Nominal(order=[\"post\", \"pre\"])\n",
    ".scale(linestyle=ses_order, marker=ses_order, fill=ses_order)\n",
    "for score, param in it.product(\n",
    "    [\"panss_p\", \"panss_n\"], [\"odi\", \"ndi\", \"fw\", \"thickness\"]\n",
    "):\n",
    "    (\n",
    "        so.Plot(\n",
    "            df[df[\"param\"].isin([param])],\n",
    "            x=score,\n",
    "            y=\"dk\",\n",
    "            group=\"session\",\n",
    "            color=\"lobe\",\n",
    "        )\n",
    "        .facet(col=\"lobe\", wrap=2, order=list(rois))\n",
    "        .add(\n",
    "            so.Dot(color=\"#666666\", pointsize=3),\n",
    "            marker=\"session\",\n",
    "            fill=\"session\",\n",
    "            legend=False,\n",
    "        )\n",
    "        .add(\n",
    "            so.Line(linewidth=1.5),\n",
    "            so.PolyFit(order=1),\n",
    "            linestyle=\"session\",\n",
    "            legend=False,\n",
    "        )\n",
    "        .layout(size=(5, 5))\n",
    "        .scale(linestyle=ses_order, marker=ses_order, fill=ses_order)\n",
    "        .label(x=titles[score], y=titles[param])\n",
    "        .theme(plt.rcParams | {\"axes.titlesize\": 14, \"axes.labelsize\": 12})\n",
    "        .label(title=rois.get, linestyle=str.capitalize, marker=str.capitalize)\n",
    "        .save(f\"~/tsclient/khangrp4/Downloads/{score}-{param}.png\")\n",
    "        # .show()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "rois = {\n",
    "    \"superiorfrontal\": \"Superior Frontal\",\n",
    "    \"rostralmiddlefrontal\": \"Rostral Middle Frontal\",\n",
    "    \"caudalmiddlefrontal\": \"Caudal Middle Frontal\",\n",
    "    \"parstriangularis\": \"Pars Triangularis\",\n",
    "    \"parsopercularis\": \"Pars Opercularis\",\n",
    "    \"parsorbitalis\": \"Pars Orbitalis\",\n",
    "    \"precentral\": \"Precentral\",\n",
    "    \"postcentral\": \"Postcentral\",\n",
    "    \"insula\": \"Insula\",\n",
    "    \"superiortemporal\": \"Superior Temporal\",\n",
    "    \"middletemporal\": \"Middle Temporal\",\n",
    "    \"precuneus\": \"Precuneus\"\n",
    "}\n",
    "_ = (\n",
    "    so.Plot(\n",
    "        df[df[\"name\"].isin(rois) & df[\"param\"].isin([\"FA\"])],\n",
    "        x=\"panss_n\",\n",
    "        y=\"dk\",\n",
    "        group=\"session\",\n",
    "        linestyle=\"session\",\n",
    "        color=\"name\",\n",
    "    )\n",
    "    .facet(col=\"name\",  wrap=2, order=list(rois))\n",
    "    .add(so.Dot(fill=None, color=\"#2f2f2f\"), marker = \"session\", legend=False)\n",
    "    .add(so.Line(), so.PolyFit(order=1), legend=False)\n",
    "    # .add(so.Line(linestyle=\"dashed\", alpha=0.5), legend=False)\n",
    "    .layout(size=(10, 15))\n",
    "    # .scale(x=so.Nominal(order=[\"pre\", \"post\"]))\n",
    "    .label(x=\"PANSS-N\", y=\"FA\")\n",
    "    .theme(plt.rcParams)\n",
    "    .label(title=rois.get)\n",
    "    .plot(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(2,1))\n",
    "\n",
    "from matplotlib import cm, colors\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "def add_legend(fig, labels, cmap=None, size=None, cmax=None, **kwargs):\n",
    "    if cmap is None:\n",
    "        cmap = cm.get_cmap(plt.rcParams[\"image.cmap\"])\n",
    "    if isinstance(cmap, colors.ListedColormap) and cmax is None:\n",
    "        cmax = len(cmap.colors)\n",
    "    colorpoints = colors.Normalize(0, cmax)(np.r_[: len(labels)])\n",
    "    handles = [\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            linestyle=\"dashed\",\n",
    "            marker=\"X\",\n",
    "            markeredgecolor=\"#666666\",\n",
    "            fillstyle=\"none\",\n",
    "            label=\"Pre\",\n",
    "            markersize=size,\n",
    "        ),\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            label=\"Post\",\n",
    "            markeredgecolor=\"#666666\",\n",
    "            markerfacecolor=\"#666666\",\n",
    "            fillstyle=\"full\",\n",
    "            markersize=size,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return fig.legend(\n",
    "        handles=handles,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "add_legend(fig, [\"Pre\", \"Post\"], loc=\"center\")\n",
    "ax.axis(False)\n",
    "\n",
    "fig.savefig(\"/home/ROBARTS/pvandyk2/tsclient/khangrp4/Downloads/clin-legend.png\", transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusters.sel(param=\"FA\", clusid=2, session=\"pre\").load().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix=\"FA\"\n",
    "# for l, clust in zip((\"C\", \"P\", \"Q\"), cluster_p):\n",
    "#     if not clust.shape and clust.item() is None:\n",
    "#         continue\n",
    "#     np.place(clust, np.logical_or(clust > 0.05, ~mask), np.nan)\n",
    "#     np.copyto(clust, slm.t[0], where=~np.isnan(clust))\n",
    "#     print(l, \"=\", np.sum(~np.isnan(clust)))\n",
    "\n",
    "keys = [\n",
    "    (\"ndi\", -1),\n",
    "    (\"fw\", 1),\n",
    "    (\"FA\", -1),\n",
    "    (\"L1\", 1),\n",
    "    (\"MD\", 1),\n",
    "    (\"RD\", 1),\n",
    "    (\"thickness\", -1),\n",
    "]\n",
    "da = stats.stack(effect=[\"suffix\", \"sign\"]).sel(effect=keys)\n",
    "\n",
    "def do_plot(data):\n",
    "    return plot_hemispheres(\n",
    "        lh,\n",
    "        rh,\n",
    "        # np.where(slm.t > 2, slm.t, np.nan),\n",
    "        # slm.t,\n",
    "        data,\n",
    "        color_bar=True,\n",
    "        # label_text=[\"ndi\"],\n",
    "        label_text=list(map(str,keys)),\n",
    "        cmap=\"viridis\",\n",
    "        embed_nb=True,\n",
    "        size=(1400, 200 * data.shape[0]),\n",
    "        zoom=1.45,\n",
    "        nan_color=(0.7, 0.7, 0.7, 1),\n",
    "        cb__labelTextProperty={\"fontSize\": 12},\n",
    "        transparent_bg=False,\n",
    "    )\n",
    "\n",
    "\n",
    "do_plot(\n",
    "    da.sel(smoothing=11, model=\"intr\")[\"C\"]\n",
    "    .where(lambda da: da < 0.05)\n",
    "    .transpose(\"effect\", \"vertex\")\n",
    "    .data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ma.mean(np.ma.masked_where(np.isnan(slm.t), slm.t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
