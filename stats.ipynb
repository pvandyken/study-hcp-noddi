{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots()\n",
    "# hack to remove hide globally installed libraries, which are the wrong R version\n",
    "from rpy2 import robjects as ro\n",
    "\n",
    "ro.r(\".libPaths('/local/scratch/noddi/lib/R/library')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from pathlib import Path\n",
    "\n",
    "import ciftipy as cp\n",
    "import colormaps as cmaps\n",
    "import dask.bag as db\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import scipy.stats as scs\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr\n",
    "from brainspace.plotting import plot_surf, plot_hemispheres\n",
    "from brainstat.datasets import fetch_mask, fetch_template_surface\n",
    "from brainstat.stats.SLM import SLM\n",
    "from brainstat.stats.terms import FixedEffect, MixedEffect\n",
    "from dask.diagnostics import ProgressBar\n",
    "from matplotlib import cm, font_manager\n",
    "from rsbids import BidsLayout\n",
    "from statannotations.Annotator import Annotator\n",
    "import rpy2_arrow.polars as rpy2polars\n",
    "import colormaps as cmaps\n",
    "from cycler import cycler\n",
    "\n",
    "from lib import atlases\n",
    "from lib.bidsarray import layout_map\n",
    "from lib.dataset import Dataset\n",
    "from lib.mesh import mesh_smooth\n",
    "from lib.demographics import DemographicTable\n",
    "from lib import polars_expr as ple\n",
    "from lib.plotting import (\n",
    "    add_colorbar,\n",
    "    add_legend,\n",
    "    comparison_plot,\n",
    "    plot_hierachical_connectome,\n",
    ")\n",
    "from lib.seaborn_stats import Lme4CI, PearsonrAnnot, PolyCI\n",
    "from styles import styles as Styles\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.style.use(\"styles/elsevier.mplstyle\")\n",
    "font_dirs = [Path.home() / \".fonts\"]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "plt.rcParams[\"axes.prop_cycle\"] = cycler(color=cmaps.colorblind_10.colors)\n",
    "so.Plot.config.theme.update(plt.rcParams)\n",
    "\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "from templateflow import api as tflow\n",
    "import rpy2.ipython.html\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "rpy2.ipython.html.init_printing()\n",
    "\n",
    "\n",
    "rutils = importr(\"utils\")\n",
    "rbase = importr(\"base\")\n",
    "lme4 = importr(\"lme4\")\n",
    "rstats = importr(\"stats\")\n",
    "pbkrtest = importr(\"pbkrtest\")\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "%R library(polars); library(tidypolars); library(tidyverse); library(\"lme4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainspace.mesh import mesh_io\n",
    "# layout = BidsLayout(\n",
    "#     [\"../../derivatives/surfsample-0.1.0/\", \"../../derivatives/snakeanat-diffusion-v0.0.1/\"],\n",
    "#     cache=\".cache\",\n",
    "#     reset_cache=True,\n",
    "# )\n",
    "hcp = (\n",
    "    Dataset(\".hcp.layout\", \"hcp\")\n",
    "    .add_phenotypes(\"hcp_metadata.yaml\")\n",
    "    .filter(pl.col(\"ddx\").is_in([1, 3]))\n",
    ")\n",
    "lh, rh = fetch_template_surface(\"fslr32k\", layer=\"vinflated\", join=False)\n",
    "def get_sphere(hemi):\n",
    "    path = tflow.get(template=\"fsLR\", density=\"32k\", suffix=\"sphere\", space=None, hemi=hemi)\n",
    "    return mesh_io.read_surface(str(path))\n",
    "lh_sphere = get_sphere(\"L\")\n",
    "rh_sphere = get_sphere(\"R\")\n",
    "mesh = fetch_template_surface(\"fslr32k\", layer=\"inflated\")\n",
    "mask = fetch_mask(\"fslr32k\")\n",
    "\n",
    "hcp.metadata = hcp.metadata.with_columns(\n",
    "    pl.sum_horizontal(\"PANSSP2\", \"PANSSN5\", \"PANSSN6\", \"PANSSN7\", \"PANSSG11\").alias(\n",
    "        \"Disorganization\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all the surface sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hems(img):\n",
    "    l = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project(0).flatten()\n",
    "    r = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project(0).flatten()\n",
    "    return l, r\n",
    "\n",
    "\n",
    "@layout_map(parallel=True, dtype=float, dims={\"vertex\": 64984})\n",
    "def load_data(path):\n",
    "    img = cp.load(path)\n",
    "    lh, rh = get_hems(img)\n",
    "    data = np.full((lh.shape[0] + rh.shape[0]), np.NaN)\n",
    "    bound = lh.shape[0]\n",
    "    data[:bound] = lh\n",
    "    data[bound:] = rh\n",
    "    return data\n",
    "\n",
    "    # jhp_surface = load_data(\n",
    "    #     jhp.layout.get(suffix=[\"curv\", \"thickness\"], den=\"32k\"),\n",
    "    #     [\"subject\", \"session\", \"suffix\"],\n",
    "    # ).to_dataset(name=\"surface\")\n",
    "    # jhp_surface.to_netcdf(\"checkpoint2.h5\")\n",
    "\n",
    "\n",
    "hcp_surface = xr.concat(\n",
    "    [\n",
    "        load_data(\n",
    "            hcp.layout.get(suffix=\"mdp\", extension=\".dscalar.nii\"),\n",
    "            [\"subject\", \"desc\"],\n",
    "        ),\n",
    "        load_data(\n",
    "            hcp.layout.filter(scope=\"hcp-preproc\").get(\n",
    "                suffix=\"thickness\", den=\"32k\", desc=\"corr\"\n",
    "            ),\n",
    "            [\"subject\", \"suffix\"],\n",
    "        ).rename(suffix=\"desc\"),\n",
    "    ],\n",
    "    dim=\"desc\",\n",
    ")\n",
    "\n",
    "with ProgressBar():\n",
    "    hcp_surface.to_netcdf(\"hcp_surface.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_surface = xr.open_dataarray(\"hcp_surface.nc\", chunks={})\n",
    "hcp_surface_smooth = xr.concat(\n",
    "    [\n",
    "        mesh_smooth(\n",
    "            hcp_surface.where(mask),\n",
    "            surf=mesh,\n",
    "            FWHM=smoothing,\n",
    "            mask=mask,\n",
    "            axis=\"vertex\",\n",
    "\n",
    "        ).expand_dims(smoothing=[smoothing])\n",
    "        for smoothing in np.r_[5:15]\n",
    "    ],\n",
    "    dim=\"smoothing\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    hcp_surface_smooth.to_netcdf(\"hcp_surface_smooth.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkmd = pd.read_csv(\"atlas-dkt_labels.tsv\", sep=\"\\t\")\n",
    "hcp_surface = xr.load_dataarray(\"hcp_surface.nc\")\n",
    "\n",
    "\n",
    "def do_sampling(ds):\n",
    "    @layout_map(\n",
    "        parallel=True,\n",
    "        dims={\"param\": ds[\"desc\"].rename(desc=\"param\"), \"roi\": dkmd[\"label\"]},\n",
    "        dtype=float,\n",
    "    )\n",
    "    def sample_dk(path):\n",
    "        dknii = cp.load(path)\n",
    "        dkatlas = np.empty(32492 * 2)\n",
    "        dkatlas[:32492] = (\n",
    "            dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project().ravel()\n",
    "        )\n",
    "        dkatlas[32492:] = (\n",
    "            dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project().ravel()\n",
    "        )\n",
    "        result = np.empty((len(ds[\"desc\"]), len(dkmd)))\n",
    "        x = ds.sel(subject=path.entities[\"subject\"])\n",
    "        for (i, param), (j, label) in it.product(\n",
    "            enumerate(ds[\"desc\"]), enumerate(dkmd[\"label\"])\n",
    "        ):\n",
    "            result[i, j] = np.mean(x.sel(desc=param)[dkatlas == label])\n",
    "        return result\n",
    "\n",
    "\n",
    "    return (\n",
    "        sample_dk(\n",
    "            hcp.layout.get(\n",
    "                suffix=\"dparc\",\n",
    "                subject=ds[\"subject\"].data,\n",
    "                atlas=\"dk\",\n",
    "                space=\"fsLR\",\n",
    "                den=\"32k\",\n",
    "            ),\n",
    "            wildcards=[\"subject\"],\n",
    "        )\n",
    "        .to_dataset(name=\"dk\")\n",
    "        .merge(dkmd.rename(columns={\"label\": \"roi\"}).set_index(\"roi\").to_xarray())\n",
    "    )\n",
    "with ProgressBar():\n",
    "    do_sampling(hcp_surface).to_netcdf(\"hcp_sample.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_surface = xr.load_dataarray(\"hcp_surface.nc\").drop_sel(subject=\"1032\")\n",
    "hcp_sampled = xr.load_dataset(\"hcp_sample.nc\").drop_sel(subject=\"1032\")\n",
    "# hcp_sampled = xr.load_dataset(\"hcp_dk_sample_fullwdith.nc\")\n",
    "\n",
    "\n",
    "def get_stds(df):\n",
    "    return df.with_columns(\n",
    "        stds=(\n",
    "            pl.col.dk.map_elements(scs.zscore, return_dtype=pl.List(float))\n",
    "            .abs()\n",
    "            .over(\"lobe\", \"param\", \"group\")\n",
    "        )\n",
    "    ).with_columns(\n",
    "        pl.col.stds.floor().cast(int).sub(1).clip(0, 5).sum().over(\"subject\")\n",
    "    )\n",
    "\n",
    "\n",
    "hcp_df = (\n",
    "    # xr.concat([pial_fw_sampled, hcp_sampled.sel(param=\"thickness\")], dim=\"param\")\n",
    "    hcp_sampled\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .filter(~pl.col.roi.is_in([4, 39]))\n",
    "    .group_by(\"subject\", \"param\", \"lobe\", \"hemisphere\")\n",
    "    .agg(pl.mean(\"dk\"))\n",
    "    .filter(pl.col.subject != \"1032\")\n",
    "    # .filter(pl.col.param.is_in([\"FA\", \"ndi\", \"odi\", \"fw\", \"thickness\"]))\n",
    "    .join(\n",
    "        hcp.metadata[\n",
    "            [\n",
    "                \"subject\",\n",
    "                \"group\",\n",
    "                \"age\",\n",
    "                \"sex\",\n",
    "                \"PANSSP\",\n",
    "                \"PANSSN\",\n",
    "                \"Disorganization\",\n",
    "                \"antipsychotic_dur\",\n",
    "            ]\n",
    "        ],\n",
    "        on=\"subject\",\n",
    "    )\n",
    "    .pipe(get_stds)\n",
    "    # .filter(~pl.col.subject.is_in([\"2004\", \"4010\"]))\n",
    ")\n",
    "std_thresh = 30\n",
    "dropped_subs = list(hcp_df.filter(pl.col.stds >= std_thresh)[\"subject\"].unique())\n",
    "# dropped_subs = []\n",
    "hcp_df = hcp_df.filter(pl.col.stds < std_thresh)\n",
    "hcp_smooth = xr.open_dataarray(\"hcp_surface_smooth.nc\", chunks={}).drop_sel(\n",
    "    subject=[*dropped_subs, \"1032\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_included = pl.col.subject.is_in(hcp_df[\"subject\"])\n",
    "\n",
    "hcp_demo_all = (\n",
    "    Dataset(\".hcp.layout\", \"hcp\", prefilter=False)\n",
    "    .add_phenotypes(\"hcp_metadata.yaml\")\n",
    "    .filter(pl.col(\"ddx\").is_in([1, 3]))\n",
    ")\n",
    "hcp_demo = hcp_demo_all.filter(hcp_included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize(label):\n",
    "    return label.replace(\"_\", \" \").capitalize()\n",
    "\n",
    "\n",
    "def prepare_session_table_hcp(table):\n",
    "    table.add_nominal(\"sex\", \"{M}/{F}\", autoformatter=capitalize)\n",
    "    table.add_scale(\"education\", autoformatter=capitalize)\n",
    "    table.add_scale(\"age\", autoformatter=capitalize)\n",
    "    table.add_nominal(\"handedness\", \"{R}/{L}\", autoformatter=capitalize)\n",
    "    table.add_scale(\"SES\")\n",
    "    table.add_nominal(\"smoke\", \"{Yes}/{No}\", autoformatter=capitalize)\n",
    "    table.add_scale(\"pack_years\", autoformatter=capitalize)\n",
    "    table.add_nominal(\n",
    "        \"cannabis_use\", \"{Yes}/{No}\", \"Cannabis User\", skip_stats=True, skip_fields=[\"HC\"]\n",
    "    )\n",
    "    table.add_scale(\n",
    "        \"antipsychotic_dur\",\n",
    "        \"Antipsychotic Duration (months)\",\n",
    "        report=\"median\",\n",
    "        skip_stats=True,\n",
    "        skip_fields=[\"HC\"],\n",
    "    )\n",
    "    table.add_scale(\n",
    "        \"total_defined_daily_dose\",\n",
    "        \"Lifetime Antipsychotics (Defined Daily Dose)\",\n",
    "        skip_stats=True,\n",
    "        skip_fields=[\"HC\"],\n",
    "    )\n",
    "    table.add_scale(\"panss-total\", \"PANSS Total\", skip_stats=True, skip_fields=[\"HC\"])\n",
    "    table.add_scale(\"PANSSP\", \"PANSS Positive\", skip_stats=True, skip_fields=[\"HC\"])\n",
    "    table.add_scale(\"PANSSN\", \"PANSS Negative\", skip_stats=True, skip_fields=[\"HC\"])\n",
    "    table.add_scale(\"PANSS-G\", \"PANSS Global\", skip_stats=True, skip_fields=[\"HC\"])\n",
    "\n",
    "\n",
    "parts = []\n",
    "table = DemographicTable(\n",
    "    hcp_demo.metadata.with_columns(\n",
    "        # pl.col.smoker.fill_null(\"no\"),\n",
    "        pl.col.antipsychotic_dur.fill_null(0),\n",
    "        pl.col.total_defined_daily_dose.fill_null(0),\n",
    "        # pl.col.ethnicity.replace(TOPSY_ETHNICITIES),\n",
    "        cannabis_use=pl.col.cannabis_exposure.replace({1: \"No\", 3: \"Yes\"}),\n",
    "        pack_years=pl.col.smoke_time * pl.col.smoke_amount / 20,\n",
    "    ).to_pandas(),\n",
    "    \"group\",\n",
    "    [\"HC\", \"Patient\"],\n",
    "    flavour=\"latex\",\n",
    ")\n",
    "prepare_session_table_hcp(table)\n",
    "\n",
    "print(\n",
    "    table.to_pandas()\n",
    "    .style.to_latex(\n",
    "        column_format=\"rllll\",\n",
    "        hrules=True,\n",
    "        multicol_align=\"c\",\n",
    "        convert_css=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Surface Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest\n",
    "\n",
    "from lib import polars_expr as ple\n",
    "\n",
    "\n",
    "def get_global_avg(ds):\n",
    "    hem_slices = [np.s_[:32492], np.s_[32492:]]\n",
    "    result = np.empty((len(hcp_surface[\"subject\"]), len(hcp_surface[\"desc\"]), 2))\n",
    "    for (i, subject), (j, param), hem in it.product(\n",
    "        enumerate(ds[\"subject\"]), enumerate(ds[\"desc\"]), range(2)\n",
    "    ):\n",
    "        result[i, j, hem] = np.mean(\n",
    "            ds.sel(subject=subject, desc=param)[hem_slices[hem]]\n",
    "        )\n",
    "\n",
    "    return xr.DataArray(\n",
    "        result,\n",
    "        coords={\"subject\": ds[\"subject\"], \"desc\": ds[\"desc\"], \"hemisphere\": [\"L\", \"R\"]},\n",
    "    ).rename(desc=\"param\")\n",
    "\n",
    "\n",
    "hcp_glob_df = (\n",
    "    # xr.concat([pial_fw_sampled, hcp_sampled.sel(param=\"thickness\")], dim=\"param\")\n",
    "    get_global_avg(hcp_surface)\n",
    "    .to_dataframe(name=\"dk\")\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .join(\n",
    "        hcp.metadata[\n",
    "            [\n",
    "                \"subject\",\n",
    "                \"group\",\n",
    "                \"age\",\n",
    "                \"sex\",\n",
    "                \"PANSSP\",\n",
    "                \"PANSSN\",\n",
    "                \"Disorganization\",\n",
    "                \"antipsychotic_dur\",\n",
    "            ]\n",
    "        ],\n",
    "        on=\"subject\",\n",
    "    )\n",
    "    .filter(~pl.col.subject.is_in([*dropped_subs, \"1032\"]))\n",
    "    # .pivot(\n",
    "    #     index=cs.exclude(\"param\", \"dk\"),\n",
    "    #     columns=\"param\",\n",
    "    #     values=\"dk\",\n",
    "    # )\n",
    ")\n",
    "hcp_glob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i hcp_glob_df -c rpy2polars.converter\n",
    "library(lmerTest)\n",
    "df <- hcp_glob_df |>\n",
    "    as_tibble() |>\n",
    "    pivot_wider(names_from=param, values_from=dk)\n",
    "    # group_by(subject) |>\n",
    "    # summarise(\n",
    "    #     across(where(is.character) & ! hemisphere, first),\n",
    "    #     across(!where(is.character), mean),\n",
    "    # )\n",
    "df\n",
    "lm1 <- lmer(fw ~ age + sex + group*hemisphere + csf + (1|subject), data=df)\n",
    "# lm.m <- lm(fw ~ scale(age) + sex + csf + group, data=df)\n",
    "# lm.mediated <- glm(as.factor(group) ~ scale(age) + sex + fw + thickness, data=df, family=binomial)\n",
    "summary(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_glob_stats = (\n",
    "    hcp_glob_df.group_by(\"param\")\n",
    "    .agg(\n",
    "        ple.lmer(\"scale(dk) ~ scale(age) + sex + hemisphere*group + (1|subject)\").alias(\n",
    "            \"stats\"\n",
    "        )\n",
    "    )\n",
    "    .unnest(\"stats\")\n",
    "    .explode(\"table\")\n",
    "    .unnest(\"table\")\n",
    "    .filter(\n",
    "        pl.col.index.is_in(\n",
    "            [\"hemisphereR\", \"groupPatient\", \"hemisphereR:groupPatient\"]\n",
    "        )\n",
    "    )\n",
    "    .with_columns(\n",
    "        pval=pl.when(\n",
    "            pl.col.index == \"groupPatient\",\n",
    "            pl.col.param.is_in([\"ndi\", \"odi\", \"fw\", \"thickness\", \"csf\"]),\n",
    "        )\n",
    "        .then(pl.col.pval / 2)\n",
    "        .otherwise(pl.col.pval)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pvalcorr=pl.col.pval.map_elements(\n",
    "            lambda a: pl.Series(multitest.multipletests(a, method=\"holm\")[1]),\n",
    "            return_dtype=pl.List(float),\n",
    "        ).over(\"param\"),\n",
    "    )\n",
    ")\n",
    "hcp_glob_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(\n",
    "    hcp_glob_stats\n",
    "    .with_columns(pl.col.param.replace({\"L1\": \"AD\", \"fw\": \"v_iso\"}))\n",
    "    .sort([\"param\", \"index\"])\n",
    "    .write_excel(\"suppl/hcp-glob-stats.xlsx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Cortical thickness is reduced in patients. Statistics computed using linear\n",
    "#|   mixed-effects models with subject as a random effect and group, hemisphere, age,\n",
    "#|   and sex as fixed effects. For each parameter, two-tailed T-tests were used to evaluate\n",
    "#|   the effect of hemisphere and group-hemisphere interaction on the parameter. One-tailed\n",
    "#|   T-tests were used for group effects on NDI, ODI, thickness (reduced in patients),\n",
    "#|   and $v_{iso}$ (increased in patients). Degrees of freedom for each comparison\n",
    "#|   was estimated using Satterthwaite's method [@satterthwaiteApproximateDistributionEstimates1946].\n",
    "#|   P-values from the three contrasts were corrected using Holm-Bonferonni corrections.\n",
    "#|   A. Average cortical thickness is significantly lower ($T(110.4)=-4.8;P<.001$) in\n",
    "#|   patients versus controls. B. Average parameter values split by hemisphere. Lines\n",
    "#|   illustrate the per-group mean differences across hemispheres. Shaded bands represent\n",
    "#|   95% CI computed by parametric boostrapping of the mixed-effects model with 1000\n",
    "#|   replicates. NDI is significantly lower in the right hemisphere ($T(103.0) = 3.5;P=.002$).\n",
    "#|   No other hemisphere or group:hemisphere interaction effects are noted.\n",
    "#| label: fig-surf-global\n",
    "_df = hcp_glob_df.pivot(\n",
    "    index=[\"subject\", \"age\", \"sex\", \"hemisphere\", \"group\", \"PANSSP\", \"PANSSN\"],\n",
    "    columns=\"param\",\n",
    "    values=\"dk\",\n",
    ").with_columns(cs.matches(\"MD|L1|RD\") * 1000)\n",
    "fig = plt.figure(figsize=(7.48, 6), layout=\"constrained\")\n",
    "panels = fig.subfigures(2, 1, height_ratios=[3.5, 2.5])\n",
    "panels[0].text(0.05, 1.02, \"A\", **Styles.panel_label)\n",
    "panels[1].text(0.05, 1.02, \"B\", **Styles.panel_label)\n",
    "\n",
    "\n",
    "ylabels = {\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"odi\": \"ODI\",\n",
    "    \"fw\": r\"$\\log{v_{iso}}$\",\n",
    "    \"thickness\": \"Thickness (mm)\",\n",
    "    \"FA\": \"FA\",\n",
    "    \"MD\": r\"MD $\\left(\\frac{\\mu m^2}{ms}\\right)$\",\n",
    "    \"RD\": r\"RD $\\left(\\frac{\\mu m^2}{ms}\\right)$\",\n",
    "    \"L1\": r\"AD $\\left(\\frac{\\mu m^2}{ms}\\right)$\",\n",
    "}\n",
    "\n",
    "axs = panels[0].subplots(2, 2)\n",
    "params = [\"thickness\", \"fw\", \"ndi\", \"odi\"]\n",
    "for i, (y, x) in enumerate(np.ndindex(2, 2)):\n",
    "    ax = axs[y, x]\n",
    "    if params[i] in {\"thickness\"}:\n",
    "        sig = {\n",
    "            (\"HC\", \"Patient\"): hcp_glob_stats.filter(\n",
    "                param=params[i], index=\"groupPatient\"\n",
    "            )[\"pvalcorr\"][0]\n",
    "        }\n",
    "    else:\n",
    "        sig = None\n",
    "    comparison_plot(\n",
    "        _df.to_pandas(),\n",
    "        y=params[i],\n",
    "        x=\"group\",\n",
    "        hue=\"group\",\n",
    "        ax=ax,\n",
    "        alpha=0.7,\n",
    "        size=3,\n",
    "        order=[\"HC\", \"Patient\"],\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        significance=sig,\n",
    "    )\n",
    "    ax.set_ylabel(ylabels[params[i]])\n",
    "    ax.set_xlabel(\"Group\" if y == 1 else \"\")\n",
    "    ax.set_xticks([1, 0])\n",
    "\n",
    "axs = panels[1].subplots(2, 2)\n",
    "params = [\"thickness\", \"fw\", \"ndi\", \"odi\"]#, \"FA\", \"MD\", \"RD\", \"L1\"]\n",
    "for i, (y, x) in enumerate(np.ndindex(2, 2)):\n",
    "    (\n",
    "        so.Plot(_df, y=params[i], x=\"hemisphere\", color=\"group\", linestyle=\"group\")\n",
    "        .add(so.Dot(pointsize=2.5, alpha=0.7, edgealpha=0), so.Jitter(), legend=False)\n",
    "        .add(so.Line(linewidth=2), so.PolyFit(1), legend=False)\n",
    "        .add(so.Band(), Lme4CI(nsims=1000), group=\"subject\", legend=False)\n",
    "        .on(axs[y, x])\n",
    "        .label(x=\"\" if y == 0 else \"Hemisphere\", y=ylabels[params[i]])\n",
    "        .scale(\n",
    "            x=so.Nominal(order=[\"L\", \"R\"]), color=so.Nominal(order=[\"HC\", \"Patient\"])\n",
    "        )\n",
    "        .plot()\n",
    "    )\n",
    "add_legend(\n",
    "    panels[1],\n",
    "    [\"HC\", \"Patient\"],\n",
    "    cmap=cmaps.colorblind_10,\n",
    "    fontsize=10,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.55, 1.1),\n",
    "    size=2.5,\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: No DTI changes in patient cortical gray matter. Statistics computed using\n",
    "#|   linear mixed-effects models with subject as a random effect and group, hemisphere,\n",
    "#|   age, and sex as fixed effects. For each parameter, two-tailed T-tests were used\n",
    "#|   to evaluate the effect of group, hemisphere, and group-hemisphere interaction on\n",
    "#|   the parameter. Degrees of freedom for each comparison was estimated using Satterthwaite's\n",
    "#|   method [@satterthwaiteApproximateDistributionEstimates1946]. P-values from the three\n",
    "#|   contrasts were corrected using Holm-Bonferonni corrections. Average parameter values\n",
    "#|   are represented split by hemisphere. Lines illustrate the per-group mean differences\n",
    "#|   across hemispheres. Shaded bands represent 95% CI computed by parametric boostrapping\n",
    "#|   of the mixed-effects model with 1000 replicates.No hemisphere or group:hemisphere\n",
    "#|   interaction effects are noted.\n",
    "#| label: fig-surf-global-dti\n",
    "_df = hcp_glob_df.pivot(\n",
    "    index=[\"subject\", \"age\", \"sex\", \"hemisphere\", \"group\", \"PANSSP\", \"PANSSN\"],\n",
    "    columns=\"param\",\n",
    "    values=\"dk\",\n",
    ").with_columns(cs.matches(\"MD|L1|RD\") * 1000)\n",
    "fig = plt.figure(figsize=(7.48, 3), layout=\"constrained\")\n",
    "\n",
    "ylabels = {\n",
    "    \"FA\": \"FA\",\n",
    "    \"MD\": r\"MD $\\left(\\frac{\\mu m^2}{ms}\\right)$\",\n",
    "    \"RD\": r\"RD $\\left(\\frac{\\mu m^2}{ms}\\right)$\",\n",
    "    \"L1\": r\"AD $\\left(\\frac{\\mu m^2}{ms}\\right)$\",\n",
    "}\n",
    "\n",
    "axs = fig.subplots(2, 2)\n",
    "params = [\"FA\", \"MD\", \"RD\", \"L1\"]\n",
    "for i, (y, x) in enumerate(np.ndindex(2, 2)):\n",
    "    (\n",
    "        so.Plot(_df, y=params[i], x=\"hemisphere\", color=\"group\", linestyle=\"group\")\n",
    "        .add(so.Dot(pointsize=3, alpha=0.7), so.Jitter(), legend=False)\n",
    "        .add(so.Line(linewidth=2), so.PolyFit(1), legend=False)\n",
    "        .add(so.Band(), Lme4CI(nsims=1000), group=\"subject\", legend=False)\n",
    "        .on(axs[y, x])\n",
    "        .label(x=\"\" if y == 0 else \"Hemisphere\", y=ylabels[params[i]])\n",
    "        .scale(\n",
    "            x=so.Nominal(order=[\"L\", \"R\"]), color=so.Nominal(order=[\"HC\", \"Patient\"])\n",
    "        )\n",
    "        .plot()\n",
    "    )\n",
    "add_legend(\n",
    "    fig,\n",
    "    [\"HC\", \"Patient\"],\n",
    "    cmap=cm.tab10,\n",
    "    fontsize=10,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.55, 0.55),\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.001)\n",
    "    .then(pl.lit(\"< .001\"))\n",
    "    .otherwise(\n",
    "        pl.col(\"pvalcorr\")\n",
    "        .round(3)\n",
    "        .round_sig_figs(2)\n",
    "        .cast(str)\n",
    "        .str.strip_chars_start(\"0\")\n",
    "    )\n",
    ")\n",
    "sig_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.05)\n",
    "    .then(pl.format(r\"\\textbf{{}}\", p_format))\n",
    "    .otherwise(p_format)\n",
    ")\n",
    "print(\n",
    "    hcp_glob_stats\n",
    "    .select(\n",
    "        pl.col.coef.round_sig_figs(2)\n",
    "        .cast(str)\n",
    "        .str.strip_chars_end(\"0\")\n",
    "        .alias(r\"$\\beta_{norm}$\"),\n",
    "        pl.col.t.round_sig_figs(2).cast(str).str.strip_chars_end(\"0\").alias(\"T\"),\n",
    "        pl.col.df.round(1).cast(str),\n",
    "        sig_format.alias(r\"$P_{corr}$\"),\n",
    "        index=pl.col.index.replace(\n",
    "            {\n",
    "                \"hemisphereR\": r\"$\\sim Hem_{right}$\",\n",
    "                \"groupPatient\": r\"$\\sim G_{patient}$\",\n",
    "                \"hemisphereR:groupPatient\": r\"$\\sim Hem_{right}:G_{patient}$\",\n",
    "            }\n",
    "        ),\n",
    "        param=pl.col.param.replace(\n",
    "            {\n",
    "                \"ndi\": \"NDI\",\n",
    "                \"fw\": r\"$v_{iso}$\",\n",
    "                \"odi\": \"ODI\",\n",
    "                \"thickness\": \"Thickness\",\n",
    "                \"csf\": \"CSF\",\n",
    "                \"L1\": \"AD\",\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index([\"param\", \"index\"])\n",
    "    .sort_index()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], axis=1)\n",
    "    .sort_index(axis=1)\n",
    "    .reindex([r\"$\\beta_{norm}$\", \"T\", \"df\", r\"$P_{corr}$\"], axis=1, level=1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"\": \"Param\", \"param\": \"\"})\n",
    "    .style.hide()\n",
    "    .to_latex(\n",
    "        column_format=\"rllllllllllll\",\n",
    "        hrules=True,\n",
    "        multicol_align=\"c\",\n",
    "        convert_css=True,\n",
    "        label=\"tbl-surf-global\",\n",
    "        caption=\"Statistics for average cortical parameters modelled against group and hemisphere.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import polars_expr as ple\n",
    "\n",
    "\n",
    "def get_ols(col, filter=None):\n",
    "    if col == \"group\":\n",
    "        contr = \"group[T.Patient]\"\n",
    "    else:\n",
    "        contr = col\n",
    "    return ple.ols(\n",
    "        f\"dk ~ {col} + age + sex + csf\",\n",
    "        contr,\n",
    "        filter=filter,\n",
    "        columns=\"param\",\n",
    "        alternative=pl.when(pl.col.param.is_in([\"fw\"]))\n",
    "        .then(pl.lit(1))\n",
    "        .when(pl.col.param.is_in([\"FA\", \"RD\", \"MD\", \"L1\", \"csf\"]))\n",
    "        .then(pl.lit(0))\n",
    "        .otherwise(pl.lit(-1)),\n",
    "    ).alias(f\"{col}_stats\")\n",
    "\n",
    "\n",
    "def get_all_stats(df):\n",
    "    return (\n",
    "        df.group_by(\"lobe\", \"param\", \"hemisphere\")\n",
    "        .agg(\n",
    "            get_ols(\"group\"),\n",
    "            # get_ols(\"PANSSP\", pl.col.group == \"Patient\"),\n",
    "            # get_ols(\"PANSSN\", pl.col.group == \"Patient\"),\n",
    "        )\n",
    "        .melt([\"param\", \"lobe\", \"hemisphere\"], cs.matches(\".*_stats\"), \"model\", \"stats\")\n",
    "        .with_columns(pl.col(\"model\").str.split(\"_\").list.first())\n",
    "        .unnest(\"stats\")\n",
    "        .with_columns(\n",
    "            pl.col(\"pval\")\n",
    "            .map_elements(\n",
    "                lambda x: pl.Series(scs.false_discovery_control(x)),\n",
    "                return_dtype=pl.List(pl.Float64),\n",
    "            )\n",
    "            .over(\"param\", \"model\")\n",
    "            .name.suffix(\"corr\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "hcp_stats = get_all_stats(hcp_df.with_columns(\n",
    "    csf=pl.col(\"dk\")\n",
    "    .filter(pl.col.param == \"csf\")\n",
    "    .first()\n",
    "    .over(\"subject\", \"lobe\", \"hemisphere\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hcp_stats\n",
    "    # .with_columns(parameter=pl.concat_str(\"score\", \"feature\", separator=\"_\"))\n",
    "    .with_columns(pl.col.param.replace({\"L1\": \"AD\", \"fw\": \"v_iso\"}))\n",
    "    .sort([\"param\", \"lobe\", \"hemisphere\", \"model\"])\n",
    "    .write_excel(\"suppl/surface-roi.xlsx\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,10), layout=\"constrained\")\n",
    "axs = fig.subplots(6, 2)\n",
    "lobes = [\"insula\", \"frontal\", \"cingulate\", \"temporal\", \"occipital\", \"parietal\"]\n",
    "for i, (y, x) in enumerate(np.ndindex(6, 2)):\n",
    "    df = hcp_df if x == 0 else hcp_nonlog\n",
    "    lm  = smf.ols(\"dk ~ group + age + sex\", df.filter(lobe=lobes[y], param='fw').to_pandas()).fit()\n",
    "    axs[y,x].hist(lm.resid)\n",
    "    axs[y,x].set_title(lobes[y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Cortical ROIs affected in early psychosis. P-values corrected for multiple\n",
    "#|   comparisons across ROIs for each parameter using FDR. Left and right hemispheres\n",
    "#|   are illustrated separately. For each hemisphere, data from healthy controls are\n",
    "#|   shown in the left curve, patients in the right. Curves correspond to kernel density\n",
    "#|   estimates with bandwidth determined using the Scott method [@scott2015multivariate].\n",
    "#|   Dashed lines represent first, second, and third quartiles. A. ROIs with significantly\n",
    "#|   higher $v_{iso}$ in both hemispheres. B. The insula has lower FA in the left hemisphere\n",
    "#|   only. Statistics shown in @tbl-surf-roi.\n",
    "#| label: fig-surf-roi\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "roi_pvalues = hcp_stats.filter(\n",
    "    pl.col.pvalcorr < 0.05, pl.col.param.is_in([\"fw\", \"FA\"]), model=\"group\"\n",
    ")[[\"param\", \"lobe\", \"hemisphere\", \"pvalcorr\"]]\n",
    "\n",
    "_df = hcp_df.pivot(\n",
    "    index=[\"subject\", \"lobe\", \"hemisphere\", \"group\"], columns=\"param\", values=\"dk\"\n",
    ")\n",
    "fig = plt.figure(figsize=(7.48, 7), layout=\"constrained\")\n",
    "axs = fig.subplots(3, 2)\n",
    "params = [\"fw\", \"fw\", \"fw\", \"fw\", \"fw\", \"FA\"]\n",
    "lobes = [\"frontal\", \"insula\", \"temporal\", \"cingulate\", \"occipital\", \"insula\"]\n",
    "labels = {\n",
    "    \"fw\": r\"$\\log{v_{iso}}$\",\n",
    "    \"FA\": \"FA\",\n",
    "}\n",
    "\n",
    "for i, (y, x) in enumerate(np.ndindex(3, 2)):\n",
    "    ax = axs[y, x]\n",
    "    __df = _df.filter(lobe=lobes[i])\n",
    "    sns.stripplot(\n",
    "        __df,\n",
    "        y=params[i],\n",
    "        x=\"hemisphere\",\n",
    "        hue=\"group\",\n",
    "        dodge=True,\n",
    "        legend=False,\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"L\", \"R\"],\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.violinplot(\n",
    "        __df,\n",
    "        y=params[i],\n",
    "        x=\"hemisphere\",\n",
    "        hue=\"group\",\n",
    "        split=True,\n",
    "        legend=False,\n",
    "        palette=([cm.tab10(0), cm.tab10(1)]),\n",
    "        alpha=0.4,\n",
    "        linecolor=\"#f0f0f0\",\n",
    "        linewidth=1,\n",
    "        inner=\"quart\",\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"L\", \"R\"],\n",
    "        ax=ax,\n",
    "        cut=0,\n",
    "    )\n",
    "    ax.set_title(lobes[i].capitalize())\n",
    "    ax.set_xlabel(\"\" if i < 4 else \"Hemisphere\")\n",
    "    ax.set_ylabel(labels[params[i]])\n",
    "    if (lett_ := {0: \"A\", 5: \"B\"}.get(i)) is not None:\n",
    "        ax.text(-0.18, 1.03, lett_, **Styles.panel_label, transform=ax.transAxes)\n",
    "    if i == 5:\n",
    "        # ax.set_facecolor(\"white\")\n",
    "        fig.patches.append(\n",
    "            plt.Rectangle(\n",
    "                (-0.2, -0.25),\n",
    "                1.3,\n",
    "                1.4,\n",
    "                transform=ax.transAxes,\n",
    "                color=\"#e0e0e0\",\n",
    "                zorder=-1,\n",
    "            )\n",
    "        )\n",
    "    hemis, pvals = roi_pvalues.filter(param=params[i], lobe=lobes[i])[\n",
    "        [\"hemisphere\", \"pvalcorr\"]\n",
    "    ]\n",
    "    annot = Annotator(\n",
    "        ax,\n",
    "        data=__df.to_pandas(),\n",
    "        y=params[i],\n",
    "        x=\"hemisphere\",\n",
    "        hue=\"group\",\n",
    "        order=[\"L\", \"R\"],\n",
    "        pairs=[((h, \"HC\"), (h, \"Patient\")) for h in hemis],\n",
    "        verbose=False,\n",
    "    )\n",
    "    annot.hide_not_significant = True\n",
    "    annot.configure(test=None).set_pvalues(pvals).annotate()\n",
    "\n",
    "add_legend(fig, [\"HC\", \"Patient\"], cmap=cm.tab10, fontsize=10, bbox_to_anchor=(0.6, 0.73))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-surf-roi\n",
    "---\n",
    "Cortical ROIs affected in early psychosis. P-values corrected for multiple comparisons across ROIs for each parameter using FDR. Left and right hemispheres are illustrated separately. For each hemisphere, data from healthy controls are shown in the left curve, patients in the right. Curves correspond to kernel density estimates with bandwidth determined using the Scott method [@scott2015multivariate]. Dashed lines represent first, second, and third quartiles. A. ROIs with significantly higher $\\nu_{iso}$ in both hemispheres. B. The insula has lower FA in the left hemisphere only. Statistics shown in @tbl-surf-roi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "p_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.001)\n",
    "    .then(pl.lit(\"< .001\"))\n",
    "    .otherwise(\n",
    "        pl.col(\"pvalcorr\")\n",
    "        .round(3)\n",
    "        .round_sig_figs(2)\n",
    "        .cast(str)\n",
    "        .str.strip_chars_start(\"0\")\n",
    "    )\n",
    ")\n",
    "sig_format = (\n",
    "    pl.when(pl.col(\"pvalcorr\") < 0.05)\n",
    "    .then(pl.format(r\"\\textbf{{}}\", p_format))\n",
    "    .otherwise(p_format)\n",
    ")\n",
    "\n",
    "\n",
    "def format_stats_table(df, label, caption):\n",
    "    df_resid = df[\"df_resid\"].cast(int)[0]\n",
    "    return (\n",
    "        df.select(\n",
    "            pl.col.param.replace({\"thickness\": \"Thickness\", \"fw\": \"$v_{iso}$\"}).alias(\n",
    "                \"Param\"\n",
    "            ),\n",
    "            pl.format(\"{}-{}\", pl.col.hemisphere, pl.col.lobe.str.to_titlecase()).alias(\n",
    "                \"Lobe\"\n",
    "            ),\n",
    "            pl.col.beta.round_sig_figs(2)\n",
    "            .cast(str)\n",
    "            .str.strip_chars_end(\"0\")\n",
    "            .alias(r\"$\\beta_{norm}$\"),\n",
    "            pl.col.statistic.round_sig_figs(2)\n",
    "            .cast(str)\n",
    "            .str.strip_chars_end(\"0\")\n",
    "            .alias(f\"$T({df_resid})$\"),\n",
    "            sig_format.alias(\"$P_{corr}$\"),\n",
    "        )\n",
    "        .to_pandas()\n",
    "        .set_index([\"Param\", \"Lobe\"])\n",
    "        .sort_index()\n",
    "        .style.to_latex(\n",
    "            column_format=\"rrlll\",\n",
    "            hrules=True,\n",
    "            multicol_align=\"c\",\n",
    "            multirow_align=\"t\",\n",
    "            convert_css=True,\n",
    "            label=label,\n",
    "            caption=caption,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\n",
    "    format_stats_table(\n",
    "        hcp_stats.filter(pl.col.pvalcorr < 0.05, model=\"group\"),\n",
    "        \"tbl-surf-roi\",\n",
    "        textwrap.dedent(\n",
    "            \"\"\"\n",
    "            ROIs with significant group effects.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Vertex-wise stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = (\n",
    "    hcp_smooth.to_dataset(name=\"data\")\n",
    "    .merge(\n",
    "        hcp.metadata[[\"subject\", \"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]]\n",
    "        .to_pandas()\n",
    "        .set_index(\"subject\"),\n",
    "        join=\"inner\",\n",
    "    )\n",
    ")\n",
    "ds_pt = ds.groupby(\"group\")[\"Patient\"]\n",
    "# ds_ = ds_.sel(subject=~np.isnan(ds_[\"PANSS-N\"]))\n",
    "\n",
    "surface = ds[\"data\"].transpose(\"desc\", \"smoothing\", \"subject\", \"vertex\")\n",
    "df = ds[[\"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]].to_dataframe()\n",
    "df_pt = ds_pt[[\"group\", \"age\", \"sex\", \"PANSSP\", \"PANSSN\"]].to_dataframe()\n",
    "term_group = FixedEffect(df[\"group\"])\n",
    "term_age = FixedEffect(df[\"age\"])\n",
    "term_sex = FixedEffect(df[\"sex\"])\n",
    "term_panssn = FixedEffect(df_pt[\"PANSSN\"])\n",
    "term_panssp = FixedEffect(df_pt[\"PANSSP\"])\n",
    "\n",
    "group_pt = np.asarray(df[\"group\"] == \"Patient\").astype(int)\n",
    "group_hc = np.asarray(df[\"group\"] == \"HC\").astype(int)\n",
    "\n",
    "models = {\n",
    "    \"group\": {\n",
    "        \"model\": term_group + term_age + term_sex,\n",
    "        \"contrast\": group_hc - group_pt,\n",
    "        \"surface\": surface,\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "from brainstat.stats.SLM import SLM\n",
    "from brainstat.stats.terms import FixedEffect, MixedEffect\n",
    "\n",
    "signs = {\n",
    "    \"fw\": -1,\n",
    "    \"thickness\": 1,\n",
    "    \"csf\": -1,\n",
    "}\n",
    "\n",
    "def compute_stats(ds):\n",
    "    smoothing = ds[\"smoothing\"].item()\n",
    "    suffix = ds[\"suffix\"].item()\n",
    "    sign = signs[suffix]\n",
    "    model = models[ds[\"model\"].item()]\n",
    "    slm = SLM(\n",
    "        model[\"model\"],\n",
    "        model[\"contrast\"] * sign,\n",
    "        mask=mask,\n",
    "        surf=\"fslr32k\",\n",
    "        correction=[\"rft\", \"fdr\"],\n",
    "        cluster_threshold=0.01,\n",
    "        two_tailed=False,\n",
    "    )\n",
    "    try:\n",
    "        slm.fit(\n",
    "            np.asanyarray(\n",
    "                model[\"surface\"].sel(desc=suffix, smoothing=smoothing).fillna(0)\n",
    "            )\n",
    "        )\n",
    "    except np.linalg.LinAlgError:\n",
    "        entries = {\n",
    "            \"C\": None,\n",
    "            \"P\": None,\n",
    "            \"Q\": None,\n",
    "            \"t\": None,\n",
    "            \"clusid\": None,\n",
    "        }\n",
    "    except IndexError as err:\n",
    "        raise Exception(f\"{smoothing=} {suffix=} {sign=} {model=}\") from err\n",
    "    else:\n",
    "        entries = {\n",
    "            \"C\": slm.P[\"pval\"][\"C\"],\n",
    "            \"P\": slm.P[\"pval\"][\"P\"],\n",
    "            \"Q\": slm.Q,\n",
    "            \"t\": slm.t,\n",
    "            \"clusid\": slm.P[\"clusid\"][0],\n",
    "        }\n",
    "    if entries[\"clusid\"] is not None:\n",
    "        entries[\"clusid\"] = entries[\"clusid\"][0]\n",
    "    for key, val in entries.items():\n",
    "        if val is None:\n",
    "            ds[key].data = np.full(ds[key].shape, np.nan)\n",
    "            continue\n",
    "        ds[key].data = val.reshape(ds[key].shape)\n",
    "    return ds\n",
    "\n",
    "\n",
    "import dask.array as da\n",
    "\n",
    "coords = {\n",
    "    \"smoothing\": hcp_smooth[\"smoothing\"].values[::2],\n",
    "    \"suffix\": [\"fw\", \"thickness\", \"csf\"],\n",
    "    \"model\": [\"group\"],\n",
    "}\n",
    "axes = {\"vertex\": 64984}\n",
    "variables = {\n",
    "    \"C\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"P\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"Q\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"t\": {\"dims\": [\"vertex\"], \"dtype\": float},\n",
    "    \"clusid\": {\"dims\": [\"vertex\"], \"dtype\": int},\n",
    "}\n",
    "dims = list(coords.keys())\n",
    "comp_vars = {}\n",
    "for label, v in variables.items():\n",
    "    shape = tuple(len(x) for x in coords.values()) + tuple(axes[d] for d in v[\"dims\"])\n",
    "    chunks = (1,) * len(coords) + tuple(axes[d] for d in v[\"dims\"])\n",
    "\n",
    "    comp_vars[label] = xr.DataArray(\n",
    "        da.empty(shape=shape, chunks=chunks, dtype=v[\"dtype\"]),\n",
    "        dims=dims + v[\"dims\"],\n",
    "        coords=coords,\n",
    "    )\n",
    "template = xr.Dataset(comp_vars)\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "stats = xr.map_blocks(compute_stats, template, template=template)\n",
    "# stats.to_csv(\"stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "with dask.config.set(num_workers = 2):\n",
    "    with ProgressBar():\n",
    "        stats.load()\n",
    "stats.to_netcdf(\"hcp_rft.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Vertex-wise stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = xr.open_dataset(\"hcp_rft.nc\", chunks={})\n",
    "stats = stats.assign(\n",
    "    ma_t=stats[\"t\"].where(stats[\"C\"] < 0.05),\n",
    "    ma_clusid=stats[\"clusid\"].where(stats[\"C\"] < 0.05),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "result = []\n",
    "for suffix in [\"fw\", \"thickness\"]:\n",
    "    x = stats.sel(smoothing=5, suffix=suffix, model=\"group\")\n",
    "    clusids = np.unique(x[\"clusid\"])\n",
    "    for i in clusids:\n",
    "        vertices = np.nonzero(x[\"clusid\"].data == i)\n",
    "        if np.mean(x[\"C\"][vertices]) <= 0.05:\n",
    "            coords.append((suffix, i.astype(int)))\n",
    "            result.append(\n",
    "                hcp_smooth.sel(\n",
    "                    smoothing=5,\n",
    "                    desc=suffix,\n",
    "                )\n",
    "                .transpose(\"vertex\", ...)[vertices]\n",
    "                .mean(\"vertex\")\n",
    "            )\n",
    "\n",
    "clusters = (\n",
    "    xr.concat(result, dim=\"concat_dim\")\n",
    "    .assign_coords(dict(concat_dim=pd.Index(coords, name=(\"suffix\", \"clusid\"))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    clusters.to_dataframe(name=\"data\")\n",
    "    .drop(columns=[\"clusid\", \"suffix\"])\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .join(hcp.metadata, on=\"subject\", how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as scr\n",
    "\n",
    "\n",
    "def get_vertex_adjacency(lh, rh):\n",
    "    npoints = lh.GetNumberOfPoints() + rh.GetNumberOfPoints()\n",
    "    conns = []\n",
    "\n",
    "    for mesh, offset in zip((lh, rh), (0, lh.GetNumberOfPoints())):\n",
    "        for i in range(mesh.GetNumberOfCells()):\n",
    "            cell = mesh.GetCell(i)\n",
    "            ids = cell.GetPointIds() + offset\n",
    "            conns.extend(it.permutations(ids, 2))\n",
    "\n",
    "    row, col = np.array(conns).T\n",
    "    data = np.full_like(row, True, dtype=bool)\n",
    "    return scr.coo_matrix((data, (row, col)), shape=(npoints, npoints))\n",
    "\n",
    "\n",
    "mesh_adj = get_vertex_adjacency(lh, rh).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(arr, iter=3):\n",
    "    dilated = np.copy(arr)\n",
    "    for _ in range(iter):\n",
    "        for i in np.unique(dilated):\n",
    "            if np.isnan(i):\n",
    "                continue\n",
    "            indices = np.unique(np.argwhere(mesh_adj[dilated == i])[:, 1])\n",
    "            dilated[indices] = i\n",
    "    return dilated\n",
    "\n",
    "def smooth(arr):\n",
    "    smoothed = np.copy(arr)\n",
    "    for i in np.unique(smoothed):\n",
    "        if np.isnan(i):\n",
    "            continue\n",
    "        mask = np.argwhere(smoothed == i).ravel()\n",
    "        isolated = (np.sum(mesh_adj[np.ix_(mask, mask)], axis=0) < 4).getA1()\n",
    "        smoothed[mask[isolated]] = np.nan\n",
    "    return smoothed\n",
    "\n",
    "clus_arr = stats.sel(smoothing=5, suffix=\"fw\", model=\"group\")[\"ma_clusid\"].load().data\n",
    "dilated = smooth(dilate(clus_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lh = lh.n_points\n",
    "statmap = stats.sel(smoothing=5, suffix=\"fw\", model=\"group\")[\"ma_t\"].load().data\n",
    "lh.append_array(statmap[:n_lh], at=\"p\", name=\"t-val\")\n",
    "rh.append_array(statmap[n_lh:], at=\"p\", name=\"t-val\")\n",
    "lh.append_array(dilated[:n_lh], at=\"p\", name=\"outline\")\n",
    "rh.append_array(dilated[n_lh:], at=\"p\", name=\"outline\")\n",
    "fw_trange = np.nanmin(statmap), np.nanmax(statmap)\n",
    "fw_img = plot_surf(\n",
    "    {\n",
    "        \"lh\": lh,\n",
    "        \"rh\": rh,\n",
    "    },\n",
    "    [\n",
    "        [\"lh\", \"lh\", \"rh\", \"rh\"],\n",
    "    ],\n",
    "    # np.where(slm.t > 2, slm.t, np.nan),\n",
    "    # slm.t,\n",
    "    [\n",
    "        [ (None, \"outline\", \"t-val\")],\n",
    "        # [(None, \"outline\", \"t-val\")],\n",
    "    ],\n",
    "    [\n",
    "        [(0, 60, 90), (-20, 180, 90), (0, -140, -90), (-40, 130, 90)],\n",
    "    ],\n",
    "    color_bar=True,\n",
    "    cmap=[\n",
    "        [\n",
    "            (\"autumn\", cmaps.dark2_8,cmaps.matter_r)\n",
    "        ],\n",
    "    ],\n",
    "    color_range=[\n",
    "        [(None, (1, 8), fw_trange)],\n",
    "    ],\n",
    "    embed_nb=True,\n",
    "    size=(1500*3, 250*3),\n",
    "    zoom=1.85,\n",
    "    nan_color=(0.7, 0.7, 0.7, 0),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    transparent_bg=False,\n",
    "    return_plotter=True,\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lh = lh.n_points\n",
    "statmap = stats.sel(smoothing=5, suffix=\"thickness\", model=\"group\")[\"ma_t\"].load().data\n",
    "lh.append_array(statmap[:n_lh], at=\"p\", name=\"t-val\")\n",
    "rh.append_array(statmap[n_lh:], at=\"p\", name=\"t-val\")\n",
    "thi_trange = np.nanmin(statmap), np.nanmax(statmap)\n",
    "thickness_img = plot_surf(\n",
    "    {\n",
    "        \"lh\": lh,\n",
    "        \"rh\": rh,\n",
    "    },\n",
    "    [\n",
    "        [\"lh\", \"lh\", \"rh\", \"rh\"],\n",
    "    ],\n",
    "    # np.where(slm.t > 2, slm.t, np.nan),\n",
    "    # slm.t,\n",
    "    [\n",
    "        [(None, \"t-val\")],\n",
    "    ],\n",
    "    [\n",
    "        [\"lateral\", \"medial\", \"medial\", \"lateral\"],\n",
    "    ],\n",
    "    color_bar=True,\n",
    "    cmap=[\n",
    "        [(\"autumn\", cm.winter)],\n",
    "    ],\n",
    "    color_range=[\n",
    "        [(None, thi_trange)],\n",
    "    ],\n",
    "    embed_nb=True,\n",
    "    size=(2000 * 3, 400 * 3),\n",
    "    zoom=1.55,\n",
    "    nan_color=(0.7, 0.7, 0.7, 0),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    transparent_bg=False,\n",
    "    return_plotter=True,\n",
    ").to_numpy()\n",
    "plt.imshow(thickness_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Cortical clusters with significantly higher $v_{iso}$ in patients. Clusters\n",
    "#|   determined with random field theory with a P-value threshold of 0.01. Significance\n",
    "#|   determined using one-tailed t-tests. A. Clusters with significantly higher $\\log{v_{iso}}$.\n",
    "#|   Colored outlines around the clusters correspond with scatter plots in B., and are\n",
    "#|   not a part of the cluster. B. $\\log{v_{iso}}$ in individual clusters. Dots show\n",
    "#|   average $\\log{v_{iso}}$ within clusters for individual subjects. Colors correspond\n",
    "#|   with the cluster outlines in A.\n",
    "#| label: fig-surf-rft\n",
    "import seaborn.objects as so\n",
    "\n",
    "fig = plt.figure(figsize=(7.48, 7.5), layout=\"constrained\")\n",
    "panela, panelb = fig.subfigures(2, 1, height_ratios=[1.5, 6])\n",
    "panela.text(0, 1, \"A\", va=\"top\", **Styles.panel_label)\n",
    "# surf_axs[0].text(\n",
    "#     -0.2, 0.75, \"Left\", **Styles.col_title, transform=surf_axs[0].transAxes\n",
    "# )\n",
    "# surf_axs[0].text(\n",
    "#     -0.2, 0.25, \"Right\", **Styles.col_title, transform=surf_axs[0].transAxes\n",
    "# )\n",
    "# add_colorbar(*fw_trange, ax=surf_axs[1], cmap=cmaps.matter_r)\n",
    "# surf_axs[1].set_ylabel(\"T-value\")\n",
    "# surf_axs[1].set_position(surf_axs[1].get_position().translated(0, -0.1))\n",
    "ax, cax = panela.subplots(1, 2, width_ratios=[40, 1])\n",
    "ax.imshow(fw_img)\n",
    "ax.axis(\"off\")\n",
    "# ax.text(\n",
    "#     -0.03, 0.5, \"Thickness\", **Styles.row_title, transform=ax.transAxes\n",
    "# )\n",
    "add_colorbar(*fw_trange, ax=cax, outline=False, cmap=cmaps.matter_r)\n",
    "cax.set_ylabel(\"T-value\")\n",
    "panelb.text(0, 1.03, \"B\", **Styles.panel_label)\n",
    "\n",
    "grid = panelb.add_gridspec(4, 2)\n",
    "clusids = df.filter(suffix=\"fw\")[\"clusid\"].unique()\n",
    "titles = [\n",
    "    \"L-Insula\",\n",
    "    \"R-Insula\",\n",
    "    \"L-Middle Temporal Gyrus\",\n",
    "    \"L-Occipital Lobe\",\n",
    "    \"R-Occipital Lobe\",\n",
    "]\n",
    "for i, pos in enumerate(grid):\n",
    "    ax = panelb.add_subplot(pos)\n",
    "    comparison_plot(\n",
    "        df.filter(pl.col.suffix == \"fw\", clusid=clusids[i]),\n",
    "        x=\"group\",\n",
    "        y=\"data\",\n",
    "        alpha=0.7,\n",
    "        color=cmaps.dark2_8(i),\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(\"\" if i < 6 else \"Group\")\n",
    "    ax.set_ylabel(r\"$\\log{v_{iso}}$\" if i % 2 == 0 else \"\")\n",
    "    # ax.set_title(titles[i], fontsize=14)\n",
    "\n",
    "# ax, cax = panelb.subplots(1, 2, width_ratios=[40, 1])\n",
    "# panelb.text(0, 1.03, \"B\", **Styles.panel_label)\n",
    "# ax.imshow(thickness_img)\n",
    "# ax.axis(\"off\")\n",
    "# ax.text(\n",
    "#     -0.03, 0.5, \"Thickness\", **Styles.row_title, transform=ax.transAxes\n",
    "# )\n",
    "# add_colorbar(*thi_trange, ax=cax, cmap=\"winter\")\n",
    "# cax.set_ylabel(\"T-value\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-surf-rft\n",
    "---\n",
    "Cortical clusters with significantly higher $\\nu_{iso}$ in patients. Clusters determined with random field theory with a P-value threshold of 0.01. Significance determined using one-tailed t-tests. A. Clusters with significantly higher $\\log{\\nu_{iso}}$. Colored outlines around the clusters correspond with scatter plots in B., and are not a part of the cluster. B. $\\log{\\nu_{iso}}$ in individual clusters. Dots show average $\\log{\\nu_{iso}}$ within clusters for individual subjects. Colors correspond with the cluster outlines in A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Cortical clusters with significantly lower thickness in patients. Clusters\n",
    "#|   were determined with random field theory with a P-value threshold of 0.01. One-tailed\n",
    "#|   t-tests were used to test for decreased thickness.\n",
    "#| label: fig-surf-thickness-rft\n",
    "import seaborn.objects as so\n",
    "\n",
    "fig = plt.figure(figsize=(7.48, 1.5), layout=\"constrained\")\n",
    "# surf_axs[0].text(\n",
    "#     -0.2, 0.75, \"Left\", **Styles.col_title, transform=surf_axs[0].transAxes\n",
    "# )\n",
    "# surf_axs[0].text(\n",
    "#     -0.2, 0.25, \"Right\", **Styles.col_title, transform=surf_axs[0].transAxes\n",
    "# )\n",
    "# add_colorbar(*fw_trange, ax=surf_axs[1], cmap=cmaps.matter_r)\n",
    "# surf_axs[1].set_ylabel(\"T-value\")\n",
    "# surf_axs[1].set_position(surf_axs[1].get_position().translated(0, -0.1))\n",
    "ax, cax = fig.subplots(1, 2, width_ratios=[40, 1])\n",
    "ax.imshow(thickness_img)\n",
    "ax.axis(\"off\")\n",
    "# ax.text(\n",
    "#     -0.03, 0.5, \"Thickness\", **Styles.row_title, transform=ax.transAxes\n",
    "# )\n",
    "add_colorbar(*thi_trange, ax=cax, outline=False, cmap=cm.winter)\n",
    "cax.set_ylabel(\"T-value\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-surf-thickness-rft\n",
    "---\n",
    "Cortical clusters with significantly lower thickness in patients. Clusters were determined with random field theory with a P-value threshold of 0.01. One-tailed t-tests were used to test for decreased thickness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_modelling = BidsLayout(\"../HCPpsych/derivatives/noddi-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "@layout_map(\n",
    "    dims={\"src\": atlases.bn246[\"Label ID\"], \"dest\": atlases.bn246[\"Label ID\"]},\n",
    "    dtype=int,\n",
    ")\n",
    "def load_h5_nbs(file):\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        try:\n",
    "            networks = f[\"nbs/con_mat\"][:]\n",
    "            # sizes = np.sum(networks.reshape(-1, networks.shape[-1]), axis=0)\n",
    "            # labels = np.argsort(sizes)[::-1] + 1\n",
    "            # return np.sum(networks * labels, axis=-1)\n",
    "            sig = np.sum(networks, axis=-1)\n",
    "        except IndexError:\n",
    "            sig = 0\n",
    "        print(f[\"nbs\"].attrs[\"pval\"])\n",
    "        return f[\"nbs/test_stat\"][:] * sig\n",
    "\n",
    "\n",
    "descs = [\n",
    "    \"\".join(x)\n",
    "    for x in it.product([\"fw\", \"ndi\", \"odi\"], [\"phenotype\", \"panssp\", \"panssn\"])\n",
    "]\n",
    "hcp_nbs = load_h5_nbs(\n",
    "    hcp_modelling.get(suffix=\"nbs\", label=[\"pos\", \"neg\"], desc=descs), [\"desc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White matter ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wm_from_rois(path, wildcards, atlases):\n",
    "    labels = list(\n",
    "        it.chain.from_iterable(\n",
    "            zip(it.repeat(i), range(np.max(atlas).astype(int) + 1))\n",
    "            for i, atlas in enumerate(atlases)\n",
    "        )\n",
    "    )\n",
    "    nlabels = len(labels)\n",
    "\n",
    "    @layout_map(parallel=True, dims={\"roi\": nlabels}, dtype=float)\n",
    "    def inner(path):\n",
    "        data = nb.load(path).get_fdata()\n",
    "        result = np.empty((nlabels,))\n",
    "        try:\n",
    "            for i in range(0, nlabels):\n",
    "                atlas_ix, ix = labels[i]\n",
    "                if ix == 0:\n",
    "                    result[i] = 0\n",
    "                    continue\n",
    "                atlas = atlases[atlas_ix]\n",
    "\n",
    "                result[i] = np.mean(data[atlas == ix])\n",
    "            return result\n",
    "        except:\n",
    "            print(path)\n",
    "            raise\n",
    "\n",
    "    return inner(path, wildcards)\n",
    "\n",
    "\n",
    "atlas_md = pl.read_csv(\"atlas-study_labels.csv\")\n",
    "\n",
    "\n",
    "def get_group_mapping():\n",
    "    groups = atlas_md.filter(group=\"core\")\n",
    "    group_id, atlas_id = atlas_md.join(\n",
    "        groups[[\"name\"]], left_on=\"group\", right_on=\"name\"\n",
    "    ).with_columns(\n",
    "        pl.col.group.replace(\n",
    "            dict(zip(*groups[[\"name\", \"atlas_id\"]])), return_dtype=pl.Int32\n",
    "        )\n",
    "    )[[\"group\", \"atlas_id\"]]\n",
    "    mapping = np.zeros(((atlas_id.max() + 1),))\n",
    "    mapping[atlas_id] = group_id\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def get_atlases(layout, dims, jhu_atlas, lobe_atlas):\n",
    "    @layout_map(parallel=True, dims=dims, dtype=float)\n",
    "    def get_skeleton(path):\n",
    "        return nb.load(path).get_fdata()\n",
    "\n",
    "    mean_skeleton = get_skeleton(layout, [\"subject\"]).mean([\"subject\"]) > 0\n",
    "    jhu_atlas, lobe_atlas = (\n",
    "        np.where(mean_skeleton, nb.load(atlas).get_fdata(), 0)\n",
    "        for atlas in (jhu_atlas, lobe_atlas)\n",
    "    )\n",
    "    core_groups = get_group_mapping().astype(int)\n",
    "    lobe_mask = np.where(jhu_atlas == 0, lobe_atlas, 0)\n",
    "    return {\n",
    "        \"lobe_mask\": lobe_mask,\n",
    "        \"jhu_atlas\": jhu_atlas,\n",
    "        \"global_mask\": (jhu_atlas > 0) | (lobe_mask > 0),\n",
    "        \"core-periph\": (jhu_atlas > 0).astype(int) + ((lobe_mask > 0).astype(int)) * 2,\n",
    "        \"core_group_mask\": core_groups[jhu_atlas.astype(int)],\n",
    "    }\n",
    "\n",
    "\n",
    "def run_roi_sampling(layout, jhu_atlas, lobe_atlas, skeleton_dims):\n",
    "    atlases = get_atlases(\n",
    "        layout.get(suffix=\"skeletonized\", desc=\"ndi\"),\n",
    "        dims=skeleton_dims,\n",
    "        jhu_atlas=jhu_atlas,\n",
    "        lobe_atlas=lobe_atlas,\n",
    "    )\n",
    "    return get_wm_from_rois(\n",
    "        layout.get(suffix=\"skeletonized\", desc=[\"ndi\", \"fw\", \"odi\", \"logfw\"]),\n",
    "        [\"subject\", \"desc\"],\n",
    "        atlases=list(atlases.values()),\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_hemispheres(layout, atlas, skeleton_dims):\n",
    "    mean_skeleton = (\n",
    "        get_mean_skeleton(\n",
    "            layout.get(suffix=\"skeletonized\", desc=\"ndi\"),\n",
    "            [\"subject\"],\n",
    "            dims=skeleton_dims,\n",
    "        ).mean([\"subject\"])\n",
    "        > 0\n",
    "    )\n",
    "    atlas = np.where(mean_skeleton, nb.load(atlas).get_fdata(), 0)\n",
    "    atlas[(atlas < 7) & (atlas % 2 == 1)] = 1\n",
    "    atlas[(atlas % 2 == 0) & (atlas != 0)] = 2\n",
    "    atlas[atlas > 2] = 0\n",
    "    return get_wm_from_rois(\n",
    "        layout.get(suffix=\"skeletonized\", desc=[\"ndi\", \"fw\", \"odi\"]),\n",
    "        [\"subject\", \"desc\"],\n",
    "        atlases=[atlas],\n",
    "    )\n",
    "\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "hcp_wm_sampled = run_roi_sampling(\n",
    "    hcp.layout.get(suffix=\"skeletonized\", datatype=False),\n",
    "    jhu_atlas=\"../HCPpsych/derivatives/atlases/atlas.nii.gz\",\n",
    "    lobe_atlas=\"../HCPpsych/derivatives/atlases/lobe-atlas.nii.gz\",\n",
    "    skeleton_dims={\"x\": 121, \"y\": 145, \"z\": 121},\n",
    ")\n",
    "\n",
    "# hcp_hemi_sampled = sample_hemispheres(\n",
    "#     hcp.layout.get(suffix=\"skeletonized\", datatype=False),\n",
    "#     atlas=\"../HCPpsych/derivatives/atlases/hemi-atlas.nii.gz\",\n",
    "#     skeleton_dims={\"x\": 121, \"y\": 145, \"z\": 121},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_atlas = \"../HCPpsych/derivatives/atlases/atlas.nii.gz\"\n",
    "lobe_atlas = \"../HCPpsych/derivatives/atlases/lobe-atlas.nii.gz\"\n",
    "atlas = \"../HCPpsych/derivatives/atlases/hemi-atlas.nii.gz\"\n",
    "\n",
    "skeleton_dims = {\"x\": 121, \"y\": 145, \"z\": 121}\n",
    "atlases = get_atlases(\n",
    "    hcp.layout.get(suffix=\"skeletonized\", desc=\"ndi\"),\n",
    "    dims=skeleton_dims,\n",
    "    jhu_atlas=jhu_atlas,\n",
    "    lobe_atlas=lobe_atlas,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "bg = \"../HCPpsych/derivatives/tpl-FA/tpl-study/tpl-study_FA.nii.gz\"\n",
    "img = nb.load(bg)\n",
    "param_map = nb.Nifti1Image(\n",
    "    atlases[\"core_group_mask\"],\n",
    "    img.affine,\n",
    "    img.header,\n",
    ")\n",
    "plotting.plot_roi(\n",
    "    param_map,\n",
    "    bg,\n",
    "    cut_coords=np.r_[-10:50:7j],\n",
    "    resampling_interpolation=\"nearest\",\n",
    "    display_mode=\"z\",\n",
    "    annotate=False,\n",
    "    colorbar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_wm_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ProgressBar():\n",
    "    hcp_wm_sampled.to_netcdf(\"hcp_wm_sampled.nc\")\n",
    "    # hcp_hemi_sampled.to_netcdf(\"hcp_hemi_sampled.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_hemi_sampled = xr.open_dataarray(\"hcp_hemi_sampled.nc\", chunks={}).drop_sel(\n",
    "    subject=\"1032\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_hemi_df = (\n",
    "    hcp_hemi_sampled.to_dataframe(name=\"data\")\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .with_columns(\n",
    "        pl.col.roi.replace(\n",
    "            {\n",
    "                1: \"L\",\n",
    "                2: \"R\",\n",
    "            },\n",
    "            return_dtype=pl.String,\n",
    "        )\n",
    "    )\n",
    "    .filter(pl.col.roi.is_in([\"L\", \"R\"]))\n",
    "    .join(hcp.metadata, on=\"subject\", how=\"inner\")\n",
    "    .pivot(\n",
    "        index=[\"subject\", \"roi\", \"group\", \"PANSSP\", \"PANSSN\", \"age\", \"sex\"],\n",
    "        columns=\"desc\",\n",
    "        values=\"data\",\n",
    "    )\n",
    ")\n",
    "\n",
    "lm = smf.mixedlm(\n",
    "    \"scale(ndi) ~ scale(age) + sex + group*roi\",\n",
    "    groups=\"subject\",\n",
    "    data=hcp_hemi_df.to_pandas(),\n",
    ").fit()\n",
    "print(lm.summary())\n",
    "lm = smf.ols(\n",
    "    \"scale(fw) ~ scale(age) + sex + group*roi\",\n",
    "    # groups=\"subject\",\n",
    "    data=hcp_hemi_df.to_pandas()\n",
    ").fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_wm_sampled = xr.open_dataarray(\"hcp_wm_sampled.nc\", chunks={}).drop_sel(\n",
    "    subject=[*dropped_subs, \"1032\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_md = pl.read_csv(\"atlas-study_labels.csv\")\n",
    "\n",
    "atlas_filters = [\n",
    "    ~pl.col(\"label\").is_in(\n",
    "        [\n",
    "            \"Med\",\n",
    "            \"Po\",\n",
    "            \"Mb\",\n",
    "            \"FTS\",\n",
    "        ]\n",
    "    ),\n",
    "    pl.col(\"group\") != \"cerebellar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_indices = dict(\n",
    "    zip(*atlas_md.filter(pl.col(\"group\").is_in([\"core\", \"global\"]))[[\"name\", \"index\"]])\n",
    ")\n",
    "\n",
    "\n",
    "def get_index(group: str):\n",
    "    return pl.lit(group_indices[group], dtype=pl.Int64)\n",
    "\n",
    "\n",
    "def prepare_wm_rois(df, index):\n",
    "    df = df.join(atlas_md.rename({\"index\": \"roi\"}), on=\"roi\").filter(*atlas_filters)\n",
    "    return (\n",
    "        df.join(atlas_md.rename({\"index\": \"roi\"}), on=\"roi\")\n",
    "        .filter(*atlas_filters)\n",
    "        .group_by(*index, \"label\")\n",
    "        .agg(\n",
    "            pl.col(\n",
    "                \"region\",\n",
    "                \"hierarchy\",\n",
    "            ).first(),\n",
    "            pl.col(\"data\").mean(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sessions(da, hx):\n",
    "    return prepare_wm_rois(\n",
    "        da.to_dataset(name=\"data\")\n",
    "        .to_dataframe()\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "        .pipe(pl.from_pandas),\n",
    "        [\"subject\", \"desc\"],\n",
    "    ).join(hx[[\"subject\", \"group\", \"age\", \"sex\", \"PANSSN\", \"PANSSP\"]], on=[\"subject\"])\n",
    "\n",
    "\n",
    "hcp_wm_df = all_sessions(\n",
    "    hcp_wm_sampled,\n",
    "    hcp.metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hcp_wm_df.filter(label=\"WM\", desc=\"fw\")[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wm_ols(col, filter=None):\n",
    "    if col == \"group\":\n",
    "        contr = \"group[T.Patient]\"\n",
    "    else:\n",
    "        contr = col\n",
    "    return ple.ols(\n",
    "        f\"data ~ {col} + age + sex\",\n",
    "        contr,\n",
    "        filter=filter,\n",
    "        columns=\"desc\",\n",
    "        alternative=pl.when(pl.col.desc == \"fw\").then(pl.lit(1)).otherwise(pl.lit(-1)),\n",
    "    ).alias(f\"{col}_stats\")\n",
    "\n",
    "\n",
    "def get_wm_stats(df):\n",
    "    return (\n",
    "        df.group_by(\"label\", \"desc\")\n",
    "        .agg(\n",
    "            get_wm_ols(\"group\"),\n",
    "            get_wm_ols(\"PANSSP\", pl.col.group == \"Patient\"),\n",
    "            get_wm_ols(\"PANSSN\", pl.col.group == \"Patient\"),\n",
    "            pl.first(\"hierarchy\"),\n",
    "        )\n",
    "        .melt([\"desc\", \"label\", \"hierarchy\"], cs.matches(\".*_stats\"), \"model\", \"stats\")\n",
    "        .with_columns(pl.col(\"model\").str.split(\"_\").list.first())\n",
    "        .unnest(\"stats\")\n",
    "        .with_columns(\n",
    "            pl.col(\"pval\")\n",
    "            .map_elements(\n",
    "                lambda x: pl.Series(scs.false_discovery_control(x)),\n",
    "                return_dtype=pl.List(pl.Float64),\n",
    "            )\n",
    "            .over(\"desc\", \"model\", \"hierarchy\")\n",
    "            .name.suffix(\"corr\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "hcp_wm_stats = get_wm_stats(hcp_wm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hcp_wm_stats\n",
    "    # .with_columns(parameter=pl.concat_str(\"score\", \"feature\", separator=\"_\"))\n",
    "    .join(\n",
    "        # atlas_md.rename({\"index\": \"roi\"}),\n",
    "        atlas_md.group_by(\"label\").agg(pl.first(\"region\")),\n",
    "        on=\"label\",\n",
    "    )\n",
    "    .filter(pl.col.desc != \"fw\")\n",
    "    .with_columns(pl.col.desc.replace({\"logfw\": \"v_iso\"}))\n",
    "    .sort([\"desc\", \"label\", \"model\"])\n",
    "    .write_excel(\"suppl/white-matter-stats.xlsx\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot WM changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: No effect of diagnosis in white matter &NODDI. Average parameter values are\n",
    "#|   represented split by core and peripheral white matter. For each split, healthy controls\n",
    "#|   are shown in the left curve, patients in the right. Curves correspond to kernel\n",
    "#|   density estimates with bandwidth determined using the Scott method [@scott2015multivariate].\n",
    "#|   Dashed lines represent first, second, and third quartiles. Diagnosis of early-stage\n",
    "#|   psychosis does not significantly affect global NDI, ODI, or $v_{iso}$.\n",
    "#| label: fig-wm\n",
    "side_title = dict(\n",
    "    x=-0.1,\n",
    "    y=0.5,\n",
    "    rotation=\"vertical\",\n",
    "    rotation_mode=\"anchor\",\n",
    "    size=10,\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    color=Styles.Colors.dark[0],\n",
    ")\n",
    "_df = hcp_wm_df.with_columns(\n",
    "    pl.col.label.replace(\n",
    "        {\"PWM\": \"Peripheral\", \"CWM\": \"Core\"}\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(7.48, 2.5), layout=\"constrained\")\n",
    "\n",
    "axs = fig.subplots(1, 3)\n",
    "params = [\"ndi\", \"odi\", \"logfw\"]\n",
    "labels = {\n",
    "    \"logfw\": r\"$\\log{v_{iso}}$\",\n",
    "    \"fw\": \"$f_{fw}$\",\n",
    "    \"ndi\": \"NDI\",\n",
    "    \"odi\": \"ODI\",\n",
    "    \"phenotype\": \"Phenotype\",\n",
    "    \"panssp\": \"PANSS30-P\",\n",
    "    \"panssn\": \"PANSS30-N\",\n",
    "}\n",
    "for i in range(3):\n",
    "    __df = _df.filter(pl.col.label.is_in([\"Peripheral\", \"Core\"]), desc=params[i])\n",
    "    ax = axs[i]\n",
    "    sns.stripplot(\n",
    "        __df,\n",
    "        y=\"data\",\n",
    "        x=\"label\",\n",
    "        hue=\"group\",\n",
    "        dodge=True,\n",
    "        legend=False,\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"Core\", \"Peripheral\"],\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.violinplot(\n",
    "        __df,\n",
    "        y=\"data\",\n",
    "        x=\"label\",\n",
    "        hue=\"group\",\n",
    "        split=True,\n",
    "        legend=False,\n",
    "        palette=([cm.tab10(0), cm.tab10(1)]),\n",
    "        alpha=0.4,\n",
    "        linecolor=\"#f0f0f0\",\n",
    "        linewidth=1,\n",
    "        inner=\"quart\",\n",
    "        hue_order=[\"HC\", \"Patient\"],\n",
    "        order=[\"Core\", \"Peripheral\"],\n",
    "        cut=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(\"Tracts\")\n",
    "    ax.set_ylabel(labels[params[i]])\n",
    "add_legend(\n",
    "    fig,\n",
    "    [\"HC\", \"Patient\"],\n",
    "    cmap=cm.tab10,\n",
    "    fontsize=10,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.63, 0.2),\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-wm\n",
    "---\n",
    "No effect of diagnosis in white matter &NODDI. Average parameter values are represented split by core and peripheral white matter. For each split, healthy controls are shown in the left curve, patients in the right. Curves correspond to kernel density estimates with bandwidth determined using the Scott method [@scott2015multivariate]. Dashed lines represent first, second, and third quartiles. Diagnosis of early-stage psychosis does not significantly affect global NDI, ODI, or $\\nu_{iso}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Voluming Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = xr.open_dataset(\"hcp_rft.nc\")\n",
    "\n",
    "fw_t = stats.sel(smoothing=5, suffix=\"fw\", model=\"group\")[\"t\"].data\n",
    "csf_t = stats.sel(smoothing=5, suffix=\"csf\", model=\"group\")[\"t\"].data\n",
    "thickness_t = stats.sel(smoothing=5, suffix=\"thickness\", model=\"group\")[\"t\"].data\n",
    "thickness = (hcp_smooth.sel(desc=\"thickness\", smoothing=5).load().data).mean(axis=0)\n",
    "fw = (hcp_smooth.sel(desc=\"fw\", smoothing=5).load().data).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lh = lh.n_points\n",
    "data = fw_t\n",
    "lh.append_array(data[:n_lh], at=\"p\", name=\"t-val\")\n",
    "rh.append_array(data[n_lh:], at=\"p\", name=\"t-val\")\n",
    "fw_trange = np.nanmin(data), np.nanmax(data)\n",
    "fw_t_img = plot_surf(\n",
    "    {\"lh\": lh, \"rh\": rh},\n",
    "    [\n",
    "        [\"lh\"],\n",
    "        [\"lh\"],\n",
    "        [\"rh\"],\n",
    "        [\"rh\"],\n",
    "    ],\n",
    "    # np.where(slm.t > 2, slm.t, np.nan),\n",
    "    # slm.t,\n",
    "    [\n",
    "        (None, \"t-val\"),\n",
    "    ],\n",
    "    [\n",
    "        [\"lateral\"],\n",
    "        [\"medial\"],\n",
    "        [\"lateral\"],\n",
    "        [\"medial\"],\n",
    "    ],\n",
    "    color_bar=True,\n",
    "    cmap=[\n",
    "        cm.viridis,\n",
    "    ],\n",
    "    # color_range=[\n",
    "    #     [tuple(fw_trange)],\n",
    "    #     [tuple(fw_trange)],\n",
    "    #     [tuple(fw_trange)],\n",
    "    #     [tuple(fw_trange)],\n",
    "    # ],\n",
    "    embed_nb=True,\n",
    "    size=(250 * 3, 700 * 3),\n",
    "    zoom=1.6,\n",
    "    nan_color=(0.7, 0.7, 0.7, 0),\n",
    "    cb__labelTextProperty={\"fontSize\": 12},\n",
    "    transparent_bg=False,\n",
    "    return_plotter=True,\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lh = lh.n_points\n",
    "def get_2by2(data):\n",
    "    lh.append_array(data[:n_lh], at=\"p\", name=\"t-val\")\n",
    "    rh.append_array(data[n_lh:], at=\"p\", name=\"t-val\")\n",
    "    return plot_surf(\n",
    "        {\"lh\": lh, \"rh\": rh},\n",
    "        [\n",
    "            [\"lh\", \"lh\"],\n",
    "            [\"rh\", \"rh\"],\n",
    "        ],\n",
    "        # np.where(slm.t > 2, slm.t, np.nan),\n",
    "        # slm.t,\n",
    "        [\n",
    "            [(None, \"t-val\"), (None, \"t-val\")],\n",
    "            [(None, \"t-val\"), (None, \"t-val\")],\n",
    "        ],\n",
    "        [\n",
    "            [\"lateral\", \"medial\"],\n",
    "            [\"lateral\", \"medial\"],\n",
    "        ],\n",
    "        color_bar=True,\n",
    "        cmap=[\n",
    "            [cm.viridis, cm.viridis],\n",
    "            [cm.viridis, cm.viridis],\n",
    "        ],\n",
    "        # color_range=[\n",
    "        #     [tuple(fw_trange)],\n",
    "        #     [tuple(fw_trange)],\n",
    "        #     [tuple(fw_trange)],\n",
    "        #     [tuple(fw_trange)],\n",
    "        # ],\n",
    "        embed_nb=True,\n",
    "        size=(400 * 3, 300 * 3),\n",
    "        zoom=1.6,\n",
    "        nan_color=(0.7, 0.7, 0.7, 0),\n",
    "        cb__labelTextProperty={\"fontSize\": 12},\n",
    "        transparent_bg=False,\n",
    "        return_plotter=True,\n",
    "    ).to_numpy()\n",
    "data = csf_t\n",
    "csf_trange = np.nanmin(data), np.nanmax(data)\n",
    "csf_t_img = get_2by2(data)\n",
    "\n",
    "data = thickness_t\n",
    "thickness_trange = np.nanmin(data), np.nanmax(data)\n",
    "thickness_t_img = get_2by2(data)\n",
    "\n",
    "data = thickness\n",
    "thickness_range = np.nanmin(data), np.nanmax(data)\n",
    "thickness_img = get_2by2(data)\n",
    "\n",
    "data = fw\n",
    "fw_range = np.nanmin(data), np.nanmax(data)\n",
    "fw_img = get_2by2(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainspace.null_models import SpinPermutations\n",
    "\n",
    "n_rand = 1000\n",
    "\n",
    "sp = SpinPermutations(n_rep=n_rand, random_state=0)\n",
    "sp.fit(lh_sphere, rh_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr in [fw, thickness, fw_t, thickness_t, csf_t]:\n",
    "    arr[~mask] = np.nan\n",
    "\n",
    "def do_rotation(arr):\n",
    "    return np.hstack(sp.randomize(arr[:lh.n_points], arr[lh.n_points:]))\n",
    "\n",
    "fw_rot = do_rotation(fw)\n",
    "fw_t_rot = do_rotation(fw_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def spin_test(arr1, rot1, arr2):\n",
    "    r_spin = np.empty(n_rand)\n",
    "    r_obs, pv_obs = spearmanr(arr1[mask], arr2[mask])\n",
    "\n",
    "    # Compute perm pval\n",
    "    for i, perm in enumerate(rot1):\n",
    "        mask_rot = mask & ~np.isnan(perm)  # Remove midline\n",
    "        r_spin[i] = spearmanr(perm[mask_rot], arr2[mask_rot])[0]\n",
    "    return r_obs, r_spin\n",
    "\n",
    "\n",
    "fw_thickness_corr, fw_thickness_spin = spin_test(fw, fw_rot, thickness)\n",
    "fw_thickness_t_corr, fw_thickness_t_spin = spin_test(fw_t, fw_t_rot, thickness_t)\n",
    "fw_csf_t_corr, fw_csf_t_spin = spin_test(fw_t, fw_t_rot, csf_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw, thickness, csf = (\n",
    "    hcp_glob_df.group_by(\"subject\", \"param\")\n",
    "    .agg(pl.mean(\"dk\"))\n",
    "    .pivot(\n",
    "        index=cs.exclude(\"param\", \"dk\"),\n",
    "        columns=\"param\",\n",
    "        values=\"dk\",\n",
    "    )[[\"fw\", \"thickness\", \"csf\"]]\n",
    ")\n",
    "print(scs.pearsonr(fw, thickness))\n",
    "print(scs.pearsonr(fw, csf))\n",
    "print(len(fw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: $v_{iso}$ findings are distinct from partial volume effects. A. Significant\n",
    "#|   correlations observed across subjects between global averages of $v_{iso}$ and\n",
    "#|   cortical thickness ($r(105)=-0.57;P<.001$) and CSF volume fraction ($r(105)=0.31;p=.001$).\n",
    "#|   Healthy controls and patients are plotted separately, but Pearson's R is calculated\n",
    "#|   over the combined sample. B.  Thickness and $v_{iso}$ maps were made by averaging\n",
    "#|   across subjects. T-value maps were made using a vertex-wise t-tests between patients\n",
    "#|   and healthy controls, using age and sex as covariates. The center column shows the\n",
    "#|   results of spin tests between parameter maps, testing for spatial correlation. 1000\n",
    "#|   replicates were performed per test. The correlation between parameters was tested\n",
    "#|   using Spearman's rank test. Red curves show kernel density estimate of null distribution.\n",
    "#|   The empirical value is represented by the vertical line. P-value shows result of\n",
    "#|   two-tailed test. The spatial distribution of thickness and $v_{iso}$ are significantly\n",
    "#|   spatially correlated, but not the T-maps that represent diagnostic effect for $v_{iso}$\n",
    "#|   and thickness, or for $v_{iso}$ and CSF volume fraction.\n",
    "#| label: fig-pve\n",
    "def perms_plot(obs, dist, *, ax):\n",
    "    sns.kdeplot(dist, color=\"red\", fill=\"red\", alpha=0.1, edgecolor=\"#ff000088\", ax=ax)\n",
    "    ax.vlines(x=obs, ymin=0, ymax=2, color=\"#222222\")\n",
    "    plt.text(\n",
    "        obs,\n",
    "        2,\n",
    "        \"P = {}\".format(np.mean(np.abs(dist) >= np.abs(obs))),\n",
    "        va=\"bottom\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7.48, 7.5), layout=\"constrained\")\n",
    "panela, panelb = fig.subfigures(2, 1, height_ratios=[2.5, 5])\n",
    "\n",
    "panela.text(0.01, 1, \"A\", va=\"top\", **Styles.panel_label)\n",
    "axs = panela.subplots(1, 2)\n",
    "params = [\"thickness\", \"csf\"]\n",
    "labels = [\"Thickness\", \"CSF\"]\n",
    "\n",
    "for i in range(2):\n",
    "    (\n",
    "        so.Plot(\n",
    "            hcp_glob_df.group_by(\"subject\", \"param\")\n",
    "            .agg(pl.mean(\"dk\"), pl.first(\"group\"))\n",
    "            .pivot(\n",
    "                index=cs.exclude(\"param\", \"dk\"),\n",
    "                columns=\"param\",\n",
    "                values=\"dk\",\n",
    "            ),\n",
    "            x=params[i],\n",
    "            y=\"fw\",\n",
    "            # color=\"group\",\n",
    "        )\n",
    "        .add(so.Dot(alpha=0.9, pointsize=2.5, edgealpha=0), color=\"group\", legend=False)\n",
    "        .add(so.Line(), so.PolyFit(1), color=\"group\", linestyle=\"group\", legend=False)\n",
    "        .add(\n",
    "            so.Band(),\n",
    "            PolyCI(nsims=1000),\n",
    "            color=\"group\",\n",
    "            legend=False,\n",
    "        )\n",
    "        .add(so.Text(halign=\"right\"), PearsonrAnnot(\"upper right\"))\n",
    "        .label(x=labels[i], y=r\"$v_{iso}$\", title=\"Global average\")\n",
    "        .on(axs[i])\n",
    "        .plot()\n",
    "    )\n",
    "add_legend(\n",
    "    panela,\n",
    "    [\"HC\", \"Patient\"],\n",
    "    cmap=cm.tab10,\n",
    "    fontsize=10,\n",
    "    size=4,\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "\n",
    "panelb.text(0.01, 1, \"B\", va=\"top\", **Styles.panel_label)\n",
    "grid = panelb.add_gridspec(3, 3)\n",
    "\n",
    "ax = panelb.add_subplot(grid[0, 1])\n",
    "perms_plot(fw_thickness_corr, fw_thickness_spin, ax=ax)\n",
    "ax.set_title(r\"$v_{iso} \\sim \\text{Thickness}$\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[1, 1])\n",
    "perms_plot(fw_thickness_t_corr, fw_thickness_t_spin, ax=ax)\n",
    "ax.set_title(r\"$T_{v_{iso}} \\sim T_{\\text{Thickness}}$\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[2, 1])\n",
    "perms_plot(fw_csf_t_corr, fw_csf_t_spin, ax=ax)\n",
    "ax.set_title(r\"$T_{v_{iso}} \\sim T_{\\text{CSF}}$\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[0, 2])\n",
    "ax.imshow(thickness_img)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Thickness\", fontweight=\"500\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[0, 0])\n",
    "ax.imshow(fw_img)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(r\"$v_{iso}$\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[1:3, 0])\n",
    "ax.imshow(fw_t_img)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(r\"$T_{v_{iso}}$\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[1, 2])\n",
    "ax.imshow(thickness_t_img)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(r\"$T_{\\text{Thickness}}$\")\n",
    "\n",
    "ax = panelb.add_subplot(grid[2, 2])\n",
    "ax.imshow(csf_t_img)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(r\"$T_{\\text{CSF}}$\")\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
